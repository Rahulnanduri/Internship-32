{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29df527e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting selenium\n",
      "  Downloading selenium-4.5.0-py3-none-any.whl (995 kB)\n",
      "Requirement already satisfied: urllib3[socks]~=1.26 in c:\\users\\ballbuster69\\anaconda3\\lib\\site-packages (from selenium) (1.26.7)\n",
      "Collecting trio~=0.17\n",
      "  Downloading trio-0.22.0-py3-none-any.whl (384 kB)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\ballbuster69\\anaconda3\\lib\\site-packages (from selenium) (2021.10.8)\n",
      "Collecting trio-websocket~=0.9\n",
      "  Downloading trio_websocket-0.9.2-py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: idna in c:\\users\\ballbuster69\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.2)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\ballbuster69\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Collecting outcome\n",
      "  Downloading outcome-1.2.0-py2.py3-none-any.whl (9.7 kB)\n",
      "Requirement already satisfied: attrs>=19.2.0 in c:\\users\\ballbuster69\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (21.2.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\ballbuster69\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\ballbuster69\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.14.6)\n",
      "Requirement already satisfied: async-generator>=1.9 in c:\\users\\ballbuster69\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.10)\n",
      "Collecting exceptiongroup>=1.0.0rc9\n",
      "  Downloading exceptiongroup-1.0.0rc9-py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: pycparser in c:\\users\\ballbuster69\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.20)\n",
      "Collecting wsproto>=0.14\n",
      "  Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\ballbuster69\\anaconda3\\lib\\site-packages (from urllib3[socks]~=1.26->selenium) (1.7.1)\n",
      "Collecting h11<1,>=0.9.0\n",
      "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Installing collected packages: outcome, h11, exceptiongroup, wsproto, trio, trio-websocket, selenium\n",
      "Successfully installed exceptiongroup-1.0.0rc9 h11-0.14.0 outcome-1.2.0 selenium-4.5.0 trio-0.22.0 trio-websocket-0.9.2 wsproto-1.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install seleniumdesignation=driver.find_element(By.CLASS_NAME,\"suggestor-input\")\n",
    "designation.send_keys(\"Data Analyst\")designation=driver.find_element(By.CLASS_NAME,\"suggestor-input\")\n",
    "designation.send_keys(\"Data Analyst\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "689b8bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "import time "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c35819",
   "metadata": {},
   "source": [
    "# Q1: Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e564a71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f2ab46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.naukri.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d1f8a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "designation=driver.find_element(By.CLASS_NAME,\"suggestor-input\")\n",
    "designation.send_keys(\"Data Analyst\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38ca9999",
   "metadata": {},
   "outputs": [],
   "source": [
    "location=driver.find_element(By.XPATH,'/html/body/div[1]/div[6]/div/div/div[5]/div/div/div/input')\n",
    "location.send_keys(\"Bangalore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2958f513",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.XPATH,'/html/body/div[1]/div[6]/div/div/div[6]')\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "746b5a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrapping job-title from the webpage\n",
    "job_title=[]\n",
    "for i in driver.find_elements(By.XPATH,'//a[@class=\"title fw500 ellipsis\"]')[0:10]:\n",
    "    job_title.append(i.text)\n",
    "    \n",
    "# Scrapping job location from the webpage\n",
    "job_location=[]\n",
    "for i in driver.find_elements(By.XPATH,'//li[@class=\"fleft grey-text br2 placeHolderLi location\"]//span')[0:10]:\n",
    "    job_location.append(i.text)\n",
    "\n",
    "# Scrapping Company Name from the webpage\n",
    "company_name=[]\n",
    "for i in driver.find_elements(By.XPATH,'//a[@class=\"subTitle ellipsis fleft\"]')[0:10]:\n",
    "    company_name.append(i.text)\n",
    "\n",
    "# Scrapping Experience from the webpage\n",
    "experience_required=[]\n",
    "for i in driver.find_elements(By.XPATH,'//li[@class=\"fleft grey-text br2 placeHolderLi experience\"]//span')[0:10]:\n",
    "    experience_required.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1a866602",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Job_Location</th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>Experience_required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru, Chennai</td>\n",
       "      <td>Latentview</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Varite</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Analyst - CRM Platform</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai, Hyderabad/Secunde...</td>\n",
       "      <td>Artech infosystem</td>\n",
       "      <td>1-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Jar</td>\n",
       "      <td>0-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hiring For Data Analyst (DA)/ Team Lead (TL) -...</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Hyderabad/Secund...</td>\n",
       "      <td>Cognizant</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Call For Clinical Data Analyst - Hyd/Bangalore...</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Hyderabad/Secund...</td>\n",
       "      <td>Cognizant</td>\n",
       "      <td>6-9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Python Data Analyst - WFH</td>\n",
       "      <td>Remote</td>\n",
       "      <td>hCapital Business Consulting Private Limited</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Payroll Transformation Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Arrow Electronics</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Payroll Transformation Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Arrow Electronics</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Master Data Management Business Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>6-8 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job_Title  \\\n",
       "0                                Senior Data Analyst   \n",
       "1                                       Data Analyst   \n",
       "2                        Data Analyst - CRM Platform   \n",
       "3                                       Data Analyst   \n",
       "4  Hiring For Data Analyst (DA)/ Team Lead (TL) -...   \n",
       "5  Call For Clinical Data Analyst - Hyd/Bangalore...   \n",
       "6                          Python Data Analyst - WFH   \n",
       "7                Payroll Transformation Data Analyst   \n",
       "8                Payroll Transformation Data Analyst   \n",
       "9            Master Data Management Business Analyst   \n",
       "\n",
       "                                        Job_Location  \\\n",
       "0                       Bangalore/Bengaluru, Chennai   \n",
       "1                                Bangalore/Bengaluru   \n",
       "2  Bangalore/Bengaluru, Mumbai, Hyderabad/Secunde...   \n",
       "3                                Bangalore/Bengaluru   \n",
       "4  Bangalore/Bengaluru, Kolkata, Hyderabad/Secund...   \n",
       "5  Bangalore/Bengaluru, Kolkata, Hyderabad/Secund...   \n",
       "6                                             Remote   \n",
       "7                                Bangalore/Bengaluru   \n",
       "8                                Bangalore/Bengaluru   \n",
       "9                                Bangalore/Bengaluru   \n",
       "\n",
       "                                   Company_Name Experience_required  \n",
       "0                                    Latentview             3-6 Yrs  \n",
       "1                                        Varite             2-5 Yrs  \n",
       "2                             Artech infosystem             1-6 Yrs  \n",
       "3                                           Jar             0-4 Yrs  \n",
       "4                                     Cognizant             3-8 Yrs  \n",
       "5                                     Cognizant             6-9 Yrs  \n",
       "6  hCapital Business Consulting Private Limited            5-10 Yrs  \n",
       "7                             Arrow Electronics            5-10 Yrs  \n",
       "8                             Arrow Electronics             3-7 Yrs  \n",
       "9                                     Accenture             6-8 Yrs  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# converting scrapped data into DataFrame\n",
    "df=pd.DataFrame({'Job_Title':job_title,'Job_Location':job_location,'Company_Name':company_name,'Experience_required':experience_required})\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f4d997",
   "metadata": {},
   "source": [
    "# Q2 : Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c4d91056",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "import time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "236c3adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "73b91984",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.naukri.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3c496429",
   "metadata": {},
   "outputs": [],
   "source": [
    "designation=driver.find_element(By.CLASS_NAME,\"suggestor-input\")\n",
    "designation.send_keys(\"Data Scientist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7af6dd19",
   "metadata": {},
   "outputs": [],
   "source": [
    "location=driver.find_element(By.XPATH,'/html/body/div[1]/div[6]/div/div/div[5]/div/div/div/input')\n",
    "location.send_keys(\"Bangalore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f6c16613",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.XPATH,'/html/body/div[1]/div[6]/div/div/div[6]')\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9fd153b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrapping job-title from the webpage\n",
    "job_title=[]\n",
    "for i in driver.find_elements(By.XPATH,'//a[@class=\"title fw500 ellipsis\"]')[0:10]:\n",
    "    job_title.append(i.text)\n",
    "    \n",
    "# Scrapping job location from the webpage\n",
    "job_location=[]\n",
    "for j in driver.find_elements(By.XPATH,'//li[@class=\"fleft grey-text br2 placeHolderLi location\"]//span')[0:10]:\n",
    "    job_location.append(j.text)\n",
    "\n",
    "# Scrapping Company Name from the webpage\n",
    "company_name=[]\n",
    "for k in driver.find_elements(By.XPATH,'//a[@class=\"subTitle ellipsis fleft\"]')[0:10]:\n",
    "    company_name.append(k.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "26b567c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Job_Location</th>\n",
       "      <th>Company_Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Science Specialist</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...</td>\n",
       "      <td>Accenture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Science Manager</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...</td>\n",
       "      <td>Accenture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mongodb Database Administrator, Maria DB or Ca...</td>\n",
       "      <td>Bangalore/Bengaluru, Hyderabad/Secunderabad, P...</td>\n",
       "      <td>Mphasis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Assistant Manager - Data Science</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai, Pune</td>\n",
       "      <td>CitiusTech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru, Hyderabad/Secunderabad, P...</td>\n",
       "      <td>Tech Mahindra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai, New Delhi, Chennai</td>\n",
       "      <td>Boston Consulting Group</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru, New Delhi, Pune, Gurgaon/...</td>\n",
       "      <td>ZS Associates</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru, Pune, Chennai</td>\n",
       "      <td>Wipro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Opportunity For Senior Data Scientist/ Busines...</td>\n",
       "      <td>Bangalore/Bengaluru, Gurgaon/Gurugram, Delhi /...</td>\n",
       "      <td>PayU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Lead ML Scientist</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai</td>\n",
       "      <td>Fractal Analytics</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job_Title  \\\n",
       "0                            Data Science Specialist   \n",
       "1                               Data Science Manager   \n",
       "2  Mongodb Database Administrator, Maria DB or Ca...   \n",
       "3                   Assistant Manager - Data Science   \n",
       "4                                     Data Scientist   \n",
       "5                              Senior Data Scientist   \n",
       "6                                     Data Scientist   \n",
       "7                              Senior Data Scientist   \n",
       "8  Opportunity For Senior Data Scientist/ Busines...   \n",
       "9                                  Lead ML Scientist   \n",
       "\n",
       "                                        Job_Location             Company_Name  \n",
       "0  Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...                Accenture  \n",
       "1  Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...                Accenture  \n",
       "2  Bangalore/Bengaluru, Hyderabad/Secunderabad, P...                  Mphasis  \n",
       "3                  Bangalore/Bengaluru, Mumbai, Pune               CitiusTech  \n",
       "4  Bangalore/Bengaluru, Hyderabad/Secunderabad, P...            Tech Mahindra  \n",
       "5    Bangalore/Bengaluru, Mumbai, New Delhi, Chennai  Boston Consulting Group  \n",
       "6  Bangalore/Bengaluru, New Delhi, Pune, Gurgaon/...            ZS Associates  \n",
       "7                 Bangalore/Bengaluru, Pune, Chennai                    Wipro  \n",
       "8  Bangalore/Bengaluru, Gurgaon/Gurugram, Delhi /...                     PayU  \n",
       "9                        Bangalore/Bengaluru, Mumbai        Fractal Analytics  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({'Job_Title':job_title,'Job_Location':job_location,'Company_Name':company_name})\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "67415d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d699cd5a",
   "metadata": {},
   "source": [
    "# Q3: In this question you have to scrape data using the filters available on the webpage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fbfcc589",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "import time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "54fc778e",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "027ea5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.naukri.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ea50c5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#entering \"Data Scientist\" in \"Skill, Designation, Companies\" field\n",
    "designation=driver.find_element(By.CLASS_NAME,\"suggestor-input \")\n",
    "designation.send_keys('Data Scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2c2d9317",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clicking the Search button\n",
    "search=driver.find_element(By.XPATH,\"/html/body/div[1]/div[6]/div/div/div[6]\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "55b023b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#applying location filter and selecting \"Delhi/NCR\" otion\n",
    "location=driver.find_element(By.XPATH,\"/html/body/div[1]/div[4]/div/section[1]/div[2]/div[5]/div[1]/span\")\n",
    "location.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bf79ca56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#applying Salary filter and selecting \"3-6 lakhs\" otion\n",
    "salary=driver.find_element(By.XPATH,\"/html/body/div[1]/div[4]/div/section[1]/div[2]/div[6]/div[2]/div[3]/label/p\")\n",
    "salary.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d4a02368",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrapping job-title from the webpage\n",
    "jtitle=[]\n",
    "for i in driver.find_elements(By.XPATH,'//a[@class=\"title fw500 ellipsis\"]')[0:10]:\n",
    "    jtitle.append(i.text)\n",
    "    \n",
    "# Scrapping job-location from the webpage\n",
    "jloc=[]\n",
    "for j in driver.find_elements(By.XPATH,'//li[@class=\"fleft grey-text br2 placeHolderLi location\"]//span')[0:10]:\n",
    "    jloc.append(j.text)\n",
    "\n",
    "# Scrapping Company name from the webpage\n",
    "comp=[]\n",
    "for k in driver.find_elements(By.XPATH,'//a[@class=\"subTitle ellipsis fleft\"]')[0:10]:\n",
    "    comp.append(k.text)\n",
    "    \n",
    "# Scrapping Experience required from the webpage\n",
    "exp=[]\n",
    "for l in  driver.find_elements(By.XPATH,'//li[@class=\"fleft grey-text br2 placeHolderLi experience\"]//span')[0:10]:\n",
    "    exp.append(l.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "95402a3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Job_Location</th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>Experience required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Science Specialist</td>\n",
       "      <td>Kolkata, Mumbai, Hyderabad/Secunderabad, Pune,...</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Science Manager</td>\n",
       "      <td>Kolkata, Mumbai, Hyderabad/Secunderabad, Pune,...</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>4-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>New Delhi, Pune, Gurgaon/Gurugram, Bangalore/B...</td>\n",
       "      <td>ZS Associates</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lead ML Scientist</td>\n",
       "      <td>Mumbai, Bangalore/Bengaluru</td>\n",
       "      <td>Fractal Analytics</td>\n",
       "      <td>6-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Module Lead - BIDW</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Mphasis</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist I</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Uber</td>\n",
       "      <td>5-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist - PSA</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Abbott</td>\n",
       "      <td>5-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Senior Analyst-Data Science</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist/AIML Engineer</td>\n",
       "      <td>Mumbai, Hyderabad/Secunderabad, Bangalore/Beng...</td>\n",
       "      <td>upGrad</td>\n",
       "      <td>0-2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Geospatial Data Engineer/Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Louis Dreyfus Commodities</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Job_Title  \\\n",
       "0             Data Science Specialist   \n",
       "1                Data Science Manager   \n",
       "2                      Data Scientist   \n",
       "3                   Lead ML Scientist   \n",
       "4                  Module Lead - BIDW   \n",
       "5                    Data Scientist I   \n",
       "6                Data Scientist - PSA   \n",
       "7         Senior Analyst-Data Science   \n",
       "8        Data Scientist/AIML Engineer   \n",
       "9  Geospatial Data Engineer/Scientist   \n",
       "\n",
       "                                        Job_Location  \\\n",
       "0  Kolkata, Mumbai, Hyderabad/Secunderabad, Pune,...   \n",
       "1  Kolkata, Mumbai, Hyderabad/Secunderabad, Pune,...   \n",
       "2  New Delhi, Pune, Gurgaon/Gurugram, Bangalore/B...   \n",
       "3                        Mumbai, Bangalore/Bengaluru   \n",
       "4                                Bangalore/Bengaluru   \n",
       "5                                Bangalore/Bengaluru   \n",
       "6                                             Mumbai   \n",
       "7                                             Mumbai   \n",
       "8  Mumbai, Hyderabad/Secunderabad, Bangalore/Beng...   \n",
       "9                                Bangalore/Bengaluru   \n",
       "\n",
       "                Company_Name Experience required  \n",
       "0                  Accenture             2-4 Yrs  \n",
       "1                  Accenture             4-7 Yrs  \n",
       "2              ZS Associates             5-8 Yrs  \n",
       "3          Fractal Analytics            6-10 Yrs  \n",
       "4                    Mphasis             5-8 Yrs  \n",
       "5                       Uber             5-7 Yrs  \n",
       "6                     Abbott             5-7 Yrs  \n",
       "7                  Accenture             5-8 Yrs  \n",
       "8                     upGrad             0-2 Yrs  \n",
       "9  Louis Dreyfus Commodities            5-10 Yrs  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# converting scrapped data into DataFrame\n",
    "df=pd.DataFrame({'Job_Title':jtitle,'Job_Location':jloc,'Company_Name':comp,'Experience required':exp})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4c22d479",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa2163fc",
   "metadata": {},
   "source": [
    "# Q4: Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1b747871",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4aed106c",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.flipkart.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8a7f03ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "close=driver.find_element(By.XPATH,'/html/body/div[2]/div/div/button')\n",
    "close.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9cfaa0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "product=driver.find_element(By.CLASS_NAME,\"_3704LK\")\n",
    "product.send_keys('Sunglasses')\n",
    "\n",
    "search=driver.find_element(By.CLASS_NAME,\"L0Z3Pu\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "edb6585f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrapping Brand detail from the webpage\n",
    "brand=[]\n",
    "for i in driver.find_elements(By.XPATH,'//div[@class=\"_2WkVRV\"]'):\n",
    "    brand.append(i.text)\n",
    "\n",
    "# Scrapping Product Description from the webpage\n",
    "pro1=[]\n",
    "for j in driver.find_elements(By.XPATH,'//a[@class=\"IRpwTa _2-ICcC\"]'):\n",
    "    pro1.append(j.text)\n",
    "    \n",
    "pro2=[]\n",
    "for j in driver.find_elements(By.XPATH,'//a[@class=\"IRpwTa\"]'):\n",
    "    pro2.append(j.text)\n",
    "    \n",
    "pro_des=pro1+pro2\n",
    "\n",
    "# Scrapping Price from the webpage\n",
    "price=[]\n",
    "for k in driver.find_elements(By.XPATH,'//div[@class=\"_30jeq3\"]'):\n",
    "    price.append(k.text)\n",
    "\n",
    "# Scrapping Discount from the webpage\n",
    "dis=[]\n",
    "for l in driver.find_elements(By.XPATH,'//div[@class=\"_3Ay6Sb\"]'):\n",
    "    dis.append(l.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3109e72c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Product Description</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ROZZETTA CRAFT</td>\n",
       "      <td>UV Protection, Gradient Round Sunglasses (Free...</td>\n",
       "      <td>₹399</td>\n",
       "      <td>80% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ROZZETTA CRAFT</td>\n",
       "      <td>UV Protection, Gradient Rectangular Sunglasses...</td>\n",
       "      <td>₹449</td>\n",
       "      <td>77% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (Free Size)</td>\n",
       "      <td>₹799</td>\n",
       "      <td>20% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SHAAH COLLECTIONS</td>\n",
       "      <td>UV Protection Round Sunglasses (54)</td>\n",
       "      <td>₹179</td>\n",
       "      <td>86% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SHAAH COLLECTIONS</td>\n",
       "      <td>UV Protection, Mirrored Wayfarer Sunglasses (54)</td>\n",
       "      <td>₹179</td>\n",
       "      <td>86% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NuVew</td>\n",
       "      <td>UV Protection Aviator Sunglasses (57)</td>\n",
       "      <td>₹198</td>\n",
       "      <td>73% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DEIXELS</td>\n",
       "      <td>Polarized, UV Protection, Riding Glasses Wayfa...</td>\n",
       "      <td>₹249</td>\n",
       "      <td>58% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ROYAL SON</td>\n",
       "      <td>UV Protection, Polarized Round Sunglasses (54)</td>\n",
       "      <td>₹538</td>\n",
       "      <td>73% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>PIRASO</td>\n",
       "      <td>UV Protection Aviator Sunglasses (54)</td>\n",
       "      <td>₹237</td>\n",
       "      <td>85% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SUNBEE</td>\n",
       "      <td>UV Protection, Polarized Wayfarer Sunglasses (...</td>\n",
       "      <td>₹283</td>\n",
       "      <td>78% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>kingsunglasses</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (Free Size)</td>\n",
       "      <td>₹199</td>\n",
       "      <td>80% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>GANSTA</td>\n",
       "      <td>Gradient, UV Protection Aviator Sunglasses (57)</td>\n",
       "      <td>₹272</td>\n",
       "      <td>86% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>LIZA ANGEL</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (Free Size)</td>\n",
       "      <td>₹199</td>\n",
       "      <td>50% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>SHAAH COLLECTIONS</td>\n",
       "      <td>UV Protection, Mirrored Wayfarer Sunglasses (54)</td>\n",
       "      <td>₹179</td>\n",
       "      <td>86% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>MODE</td>\n",
       "      <td>UV Protection Aviator Sunglasses (Free Size)</td>\n",
       "      <td>₹179</td>\n",
       "      <td>77% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ROYAL SON</td>\n",
       "      <td>Polarized, UV Protection Aviator Sunglasses (57)</td>\n",
       "      <td>₹599</td>\n",
       "      <td>70% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>SHAAH COLLECTIONS</td>\n",
       "      <td>UV Protection Aviator Sunglasses (54)</td>\n",
       "      <td>₹179</td>\n",
       "      <td>82% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>New Specs</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (Free Size)</td>\n",
       "      <td>₹264</td>\n",
       "      <td>89% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>SHAAH COLLECTIONS</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (Free Size)</td>\n",
       "      <td>₹179</td>\n",
       "      <td>82% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>LIZA ANGEL</td>\n",
       "      <td>UV Protection, Polarized Rectangular Sunglasse...</td>\n",
       "      <td>₹261</td>\n",
       "      <td>73% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>PIRASO</td>\n",
       "      <td>UV Protection Aviator Sunglasses (58)</td>\n",
       "      <td>₹305</td>\n",
       "      <td>88% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>by Lenskart Polarized, UV Protection Cat-eye S...</td>\n",
       "      <td>₹599</td>\n",
       "      <td>70% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>PIRASO</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (52)</td>\n",
       "      <td>₹246</td>\n",
       "      <td>84% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>ROYAL SON</td>\n",
       "      <td>UV Protection, Polarized Round Sunglasses (54)</td>\n",
       "      <td>₹524</td>\n",
       "      <td>73% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>NuVew</td>\n",
       "      <td>UV Protection, Mirrored Wayfarer Sunglasses (57)</td>\n",
       "      <td>₹157</td>\n",
       "      <td>82% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>ROYAL SON</td>\n",
       "      <td>Polarized, UV Protection Aviator Sunglasses (58)</td>\n",
       "      <td>₹561</td>\n",
       "      <td>71% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>NuVew</td>\n",
       "      <td>UV Protection, Mirrored Aviator Sunglasses (57)</td>\n",
       "      <td>₹168</td>\n",
       "      <td>77% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>ROYAL SON</td>\n",
       "      <td>Polarized, UV Protection Round Sunglasses (52)</td>\n",
       "      <td>₹599</td>\n",
       "      <td>70% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Shield Sunglasses (Free Size)</td>\n",
       "      <td>₹719</td>\n",
       "      <td>20% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>by Lenskart Polarized, UV Protection Aviator S...</td>\n",
       "      <td>₹699</td>\n",
       "      <td>65% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Sewell</td>\n",
       "      <td>Mirrored, Night Vision, UV Protection, Riding ...</td>\n",
       "      <td>₹279</td>\n",
       "      <td>81% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>ROYAL SON</td>\n",
       "      <td>UV Protection Rectangular, Retro Square Sungla...</td>\n",
       "      <td>₹424</td>\n",
       "      <td>71% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (Free Size)</td>\n",
       "      <td>₹869</td>\n",
       "      <td>13% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>Gradient, UV Protection Wayfarer Sunglasses (F...</td>\n",
       "      <td>₹719</td>\n",
       "      <td>20% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>Gradient, UV Protection Wayfarer Sunglasses (F...</td>\n",
       "      <td>₹679</td>\n",
       "      <td>15% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>GANSTA</td>\n",
       "      <td>UV Protection, Gradient Aviator Sunglasses (57)</td>\n",
       "      <td>₹249</td>\n",
       "      <td>80% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>SHAAH COLLECTIONS</td>\n",
       "      <td>UV Protection Round Sunglasses (52)</td>\n",
       "      <td>₹179</td>\n",
       "      <td>87% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Aviator Sunglasses (58)</td>\n",
       "      <td>₹1,169</td>\n",
       "      <td>10% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Wrap-around Sunglasses (Free Size)</td>\n",
       "      <td>₹719</td>\n",
       "      <td>20% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Singco India</td>\n",
       "      <td>Riding Glasses, UV Protection Clubmaster, Wayf...</td>\n",
       "      <td>₹321</td>\n",
       "      <td>83% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Brand                                Product Description  \\\n",
       "0      ROZZETTA CRAFT  UV Protection, Gradient Round Sunglasses (Free...   \n",
       "1      ROZZETTA CRAFT  UV Protection, Gradient Rectangular Sunglasses...   \n",
       "2            Fastrack      UV Protection Wayfarer Sunglasses (Free Size)   \n",
       "3   SHAAH COLLECTIONS                UV Protection Round Sunglasses (54)   \n",
       "4   SHAAH COLLECTIONS   UV Protection, Mirrored Wayfarer Sunglasses (54)   \n",
       "5               NuVew              UV Protection Aviator Sunglasses (57)   \n",
       "6             DEIXELS  Polarized, UV Protection, Riding Glasses Wayfa...   \n",
       "7           ROYAL SON     UV Protection, Polarized Round Sunglasses (54)   \n",
       "8              PIRASO              UV Protection Aviator Sunglasses (54)   \n",
       "9              SUNBEE  UV Protection, Polarized Wayfarer Sunglasses (...   \n",
       "10     kingsunglasses   UV Protection Rectangular Sunglasses (Free Size)   \n",
       "11             GANSTA    Gradient, UV Protection Aviator Sunglasses (57)   \n",
       "12         LIZA ANGEL      UV Protection Wayfarer Sunglasses (Free Size)   \n",
       "13  SHAAH COLLECTIONS   UV Protection, Mirrored Wayfarer Sunglasses (54)   \n",
       "14               MODE       UV Protection Aviator Sunglasses (Free Size)   \n",
       "15          ROYAL SON   Polarized, UV Protection Aviator Sunglasses (57)   \n",
       "16  SHAAH COLLECTIONS              UV Protection Aviator Sunglasses (54)   \n",
       "17          New Specs   UV Protection Rectangular Sunglasses (Free Size)   \n",
       "18  SHAAH COLLECTIONS   UV Protection Rectangular Sunglasses (Free Size)   \n",
       "19         LIZA ANGEL  UV Protection, Polarized Rectangular Sunglasse...   \n",
       "20             PIRASO              UV Protection Aviator Sunglasses (58)   \n",
       "21      VINCENT CHASE  by Lenskart Polarized, UV Protection Cat-eye S...   \n",
       "22             PIRASO          UV Protection Rectangular Sunglasses (52)   \n",
       "23          ROYAL SON     UV Protection, Polarized Round Sunglasses (54)   \n",
       "24              NuVew   UV Protection, Mirrored Wayfarer Sunglasses (57)   \n",
       "25          ROYAL SON   Polarized, UV Protection Aviator Sunglasses (58)   \n",
       "26              NuVew    UV Protection, Mirrored Aviator Sunglasses (57)   \n",
       "27          ROYAL SON     Polarized, UV Protection Round Sunglasses (52)   \n",
       "28           Fastrack        UV Protection Shield Sunglasses (Free Size)   \n",
       "29      VINCENT CHASE  by Lenskart Polarized, UV Protection Aviator S...   \n",
       "30             Sewell  Mirrored, Night Vision, UV Protection, Riding ...   \n",
       "31          ROYAL SON  UV Protection Rectangular, Retro Square Sungla...   \n",
       "32           Fastrack      UV Protection Wayfarer Sunglasses (Free Size)   \n",
       "33           Fastrack  Gradient, UV Protection Wayfarer Sunglasses (F...   \n",
       "34           Fastrack  Gradient, UV Protection Wayfarer Sunglasses (F...   \n",
       "35             GANSTA    UV Protection, Gradient Aviator Sunglasses (57)   \n",
       "36  SHAAH COLLECTIONS                UV Protection Round Sunglasses (52)   \n",
       "37           Fastrack              UV Protection Aviator Sunglasses (58)   \n",
       "38           Fastrack   UV Protection Wrap-around Sunglasses (Free Size)   \n",
       "39       Singco India  Riding Glasses, UV Protection Clubmaster, Wayf...   \n",
       "\n",
       "     Price Discount  \n",
       "0     ₹399  80% off  \n",
       "1     ₹449  77% off  \n",
       "2     ₹799  20% off  \n",
       "3     ₹179  86% off  \n",
       "4     ₹179  86% off  \n",
       "5     ₹198  73% off  \n",
       "6     ₹249  58% off  \n",
       "7     ₹538  73% off  \n",
       "8     ₹237  85% off  \n",
       "9     ₹283  78% off  \n",
       "10    ₹199  80% off  \n",
       "11    ₹272  86% off  \n",
       "12    ₹199  50% off  \n",
       "13    ₹179  86% off  \n",
       "14    ₹179  77% off  \n",
       "15    ₹599  70% off  \n",
       "16    ₹179  82% off  \n",
       "17    ₹264  89% off  \n",
       "18    ₹179  82% off  \n",
       "19    ₹261  73% off  \n",
       "20    ₹305  88% off  \n",
       "21    ₹599  70% off  \n",
       "22    ₹246  84% off  \n",
       "23    ₹524  73% off  \n",
       "24    ₹157  82% off  \n",
       "25    ₹561  71% off  \n",
       "26    ₹168  77% off  \n",
       "27    ₹599  70% off  \n",
       "28    ₹719  20% off  \n",
       "29    ₹699  65% off  \n",
       "30    ₹279  81% off  \n",
       "31    ₹424  71% off  \n",
       "32    ₹869  13% off  \n",
       "33    ₹719  20% off  \n",
       "34    ₹679  15% off  \n",
       "35    ₹249  80% off  \n",
       "36    ₹179  87% off  \n",
       "37  ₹1,169  10% off  \n",
       "38    ₹719  20% off  \n",
       "39    ₹321  83% off  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# converting 1st page scrapped data into DataFrame\n",
    "df=pd.DataFrame({'Brand':brand,'Product Description':pro_des,'Price':price,'Discount':dis})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ea63e6",
   "metadata": {},
   "source": [
    "# Q5: Scrape 100 reviews data from flipkart.com for iphone11 phone.# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cbee77ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6ea9c816",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.flipkart.com/apple-iphone-11-black-128-gb/product-reviews/itmf1f0a58f1ecd7?pid=MOBFWBYZK3HACR72&lid=LSTMOBFWBYZK3HACR72PX4KSA&mar')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cd61fb81",
   "metadata": {},
   "outputs": [],
   "source": [
    "rate1=[]\n",
    "rate2=[]\n",
    "summary=[]\n",
    "f_rev=[]\n",
    "\n",
    "# for scrapping data from different pages to get first 100 reviews, defining Start & End of the page\n",
    "start=0\n",
    "end=15\n",
    "for page in range(start,end):\n",
    "    \n",
    "# Scrapping rating from different pages \n",
    "    for i in driver.find_elements(By.XPATH,'//div[@class=\"_3LWZlK _1BLPMq\"]'):\n",
    "        rate1.append(i.text)\n",
    "        \n",
    "    for i in driver.find_elements(By.XPATH,'//div[@class=\"_3LWZlK _1rdVr6 _1BLPMq\"]'):\n",
    "        rate2.append(i.text)\n",
    "    rate=rate1+rate2\n",
    "\n",
    "# Scrapping Review Summary from different pages\n",
    "    for j in driver.find_elements(By.XPATH,'//p[@class=\"_2-N8zT\"]'):\n",
    "        summary.append(j.text)\n",
    "        \n",
    "# Scrapping Full Review from different pages\n",
    "    for k in driver.find_elements(By.XPATH,'//div[@class=\"t-ZTKy\"]'):\n",
    "        f_rev.append(k.text)\n",
    "        \n",
    "#scraping the list of reviews data from different pages\n",
    "    nxt_button=driver.find_elements(By.XPATH,'//a[@class=\"_1LKTO3\"]')\n",
    "    try:\n",
    "        driver.get(nxt_button[1].get_attribute('href')) #getting the link from the list for next page\n",
    "    except:\n",
    "        driver.get(nxt_button[0].get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b99d9da3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review Summary</th>\n",
       "      <th>Full Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Terrific</td>\n",
       "      <td>Wow superb camera phone\\nVery smooth speed and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>The brand is very trustworthy and i got genuin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Terrific purchase</td>\n",
       "      <td>Awesome phone … value for money.. Happy with b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Mind-blowing purchase</td>\n",
       "      <td>Guys ,this is just Beast at Every Aspect of Co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Awesome</td>\n",
       "      <td>Excellent product worth for every penny, writi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>5</td>\n",
       "      <td>Just wow!</td>\n",
       "      <td>This is my first iPhone after being an android...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5</td>\n",
       "      <td>Best in the market!</td>\n",
       "      <td>Perfect iPhone . Glad that I Pick iPhone 12 in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>5</td>\n",
       "      <td>Fabulous!</td>\n",
       "      <td>Good experience iPhone 12 mobile\\nCamera clari...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5</td>\n",
       "      <td>Awesome</td>\n",
       "      <td>This was my second iphone after the xr and i c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>4</td>\n",
       "      <td>Awesome</td>\n",
       "      <td>I have been using iPhone 12 from past 10 days....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rating         Review Summary  \\\n",
       "0       5               Terrific   \n",
       "1       5       Perfect product!   \n",
       "2       5      Terrific purchase   \n",
       "3       5  Mind-blowing purchase   \n",
       "4       5                Awesome   \n",
       "..    ...                    ...   \n",
       "95      5              Just wow!   \n",
       "96      5    Best in the market!   \n",
       "97      5              Fabulous!   \n",
       "98      5                Awesome   \n",
       "99      4                Awesome   \n",
       "\n",
       "                                          Full Review  \n",
       "0   Wow superb camera phone\\nVery smooth speed and...  \n",
       "1   The brand is very trustworthy and i got genuin...  \n",
       "2   Awesome phone … value for money.. Happy with b...  \n",
       "3   Guys ,this is just Beast at Every Aspect of Co...  \n",
       "4   Excellent product worth for every penny, writi...  \n",
       "..                                                ...  \n",
       "95  This is my first iPhone after being an android...  \n",
       "96  Perfect iPhone . Glad that I Pick iPhone 12 in...  \n",
       "97  Good experience iPhone 12 mobile\\nCamera clari...  \n",
       "98  This was my second iphone after the xr and i c...  \n",
       "99  I have been using iPhone 12 from past 10 days....  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# converting scrapped data for first 100 reviews into DataFrame\n",
    "review=pd.DataFrame({'Rating':rate,'Review Summary':summary,'Full Review':f_rev})\n",
    "review.head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49af8b90",
   "metadata": {},
   "source": [
    "# Q6: Scrape data for first 100 sneakers you find when you visit flipkart.com and search for “sneakers” in the search field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e099a869",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "13d16501",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.flipkart.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "eff6642f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#entering \"sneakers\" in \"search for products\" field\n",
    "product=driver.find_element(By.CLASS_NAME,\"_3704LK\")\n",
    "product.send_keys('sneakers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7e224b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clicking the Search button\n",
    "search=driver.find_element(By.CLASS_NAME,\"L0Z3Pu\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4620b6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#introducing list for brand, product description, price & discount\n",
    "brand=[]\n",
    "prod=[]\n",
    "price=[]\n",
    "discount=[]\n",
    "\n",
    "# for scrapping data from different pages to get first 100 reviews, defining Start & End of the page\n",
    "for page in range(0,3):\n",
    "    \n",
    "# Scrapping brand list from different pages \n",
    "    for i in driver.find_elements(By.XPATH,'//div[@class=\"_2WkVRV\"]'):\n",
    "        brand.append(i.text)\n",
    "        \n",
    "# Scrapping product description from different pages \n",
    "    for j in driver.find_elements(By.XPATH,'//a[@class=\"IRpwTa\"]'):\n",
    "        prod1.append(j.text)\n",
    "    \n",
    "# Scrapping price from different pages \n",
    "    for k in driver.find_elements(By.XPATH,'//div[@class=\"_30jeq3\"]'):\n",
    "        price.append(k.text)\n",
    "        \n",
    "# Scrapping discount from different pages \n",
    "    for l in driver.find_elements(By.XPATH,'//div[@class=\"_3Ay6Sb\"]'):\n",
    "        discount.append(l.text)\n",
    "        \n",
    "#scraping the required data from different pages\n",
    "    nxt_button=driver.find_elements(By.XPATH,'//a[@class=\"_1LKTO3\"]')\n",
    "    try:\n",
    "        driver.get(nxt_button[1].get_attribute('href'))\n",
    "    except:\n",
    "        driver.get(nxt_button[0].get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420c33f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Sneaker_data=pd.DataFrame({'Brand':brand,'Product Description':prod,'Price':price,'Discount':discount})\n",
    "Sneaker_data.head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e0052cb",
   "metadata": {},
   "source": [
    "# Q7: Go to the link - https://www.myntra.com/shoes\n",
    "And then scrape First 100 shoes data you get. The data should include “Brand” of the shoes , Short Shoe description, price of the shoe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6795a12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "import time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9b0685ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0c2115d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.myntra.com/shoes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5428694e",
   "metadata": {},
   "outputs": [],
   "source": [
    "price_filter=driver.find_element(By.XPATH,\"//ul[@class='price-list']/li[2]/label/div\")\n",
    "price_filter.click()\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "15a1442a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selecting required filter of colour black\n",
    "colour_filter=driver.find_element(By.XPATH,\"//span[@data-colorhex='black']\")\n",
    "colour_filter.text\n",
    "colour_filter.click()\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "55a1787f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting required filter of price\n",
    "\n",
    "price_filter=driver.find_element(By.XPATH,\"//ul[@class='price-list']/li[2]/label/div\")\n",
    "price_filter.click()\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6ce2eb94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Red Tape', 'PUMA Motorsport', 'El Paso', 'Roadster', 'HRX by Hrithik Roshan', 'Puma', 'Red Tape', 'HRX by Hrithik Roshan', 'Red Tape', 'Roadster', 'U.S. Polo Assn.', 'Puma', 'Campus', 'Puma', 'El Paso', 'Skechers', 'HRX by Hrithik Roshan', 'U.S. Polo Assn.', 'Provogue', 'Red Tape', 'Eego Italy', 'Roadster', 'U.S. Polo Assn.', 'Puma', 'GRIFFIN', 'Kiana', 'one8 x PUMA', 'El Paso', 'Reebok', 'Red Tape', 'Puma', 'MENGLER', 'Red Tape', 'Campus', 'Puma', 'Power', 'Roadster', 'Puma', 'Fentacia', 'HRX by Hrithik Roshan', 'Campus', 'El Paso', 'HRX by Hrithik Roshan', 'GRIFFIN', 'Roadster', 'U.S. Polo Assn.', 'Skechers', 'Puma', 'Red Tape', 'FURO by Red Chief']\n",
      "['Men Walking Shoes', 'Men AMG Petronas F1 Sneakers', 'Woven Design Slip-On Sneakers', 'Men Sneakers', 'Men Aqua Shoes', 'Men Running Shoes', 'Men Walking Shoes', 'Men Street Run 2.0 Shoe', 'Men Walking Shoes', 'Men Casual Sneakers', 'Men Solid Horsebit Loafers', 'Men SoftFoam Running', 'Men Running Shoes', 'Flex Essential Running Shoes', 'Women Flat Boots', 'Men Go Run Fast Training Shoes', 'Men TR-100 Training Shoe', 'Men Sneakers', 'Men Black Solid Formal Debys', 'Men Solid Leather Formal Derbys', 'Men Trekking Shoes', 'Men Textured Sneakers', 'Men MONTON 4.0 Sneakers', 'Men Running Shoes', 'Men Perforations Fashion', 'Women Mules Flats', 'Men Printed Slip-On Sneakers', 'Women Flat Boots', 'Men Edgility Running Shoes', 'Walking Shoes', 'Men Sneakers', 'Men Walking Shoes', 'Men Walking Shoes', 'Men Road Running Shoes', 'Men Solid Running Shoes', 'Men Running Shoes', 'Men Solid Sneakers', 'Prowl Training or Gym Shoes', 'Men Woven Flat Boots', 'Men Rep Flex-1 Training Shoes', 'Men Running Shoes', 'Women Solid Heeled Boots', 'Men Aqua Shoes', 'Men Printed Slip-On Sneakers', 'Men Sneakers', 'Men Textured PU Loafers', 'Men Go Walk Walking Shoes', 'Unisex Sneakers', 'Men Walking Shoes', 'Men Running Shoes']\n",
      "['Rs. 1559Rs. 5199', 'Rs. 6399Rs. 7999', 'Rs. 799Rs. 3495', 'Rs. 872Rs. 3795', 'Rs. 1169Rs. 2599', 'Rs. 1999Rs. 3999', 'Rs. 1469Rs. 4899', 'Rs. 1999Rs. 4999', 'Rs. 1739Rs. 5799', 'Rs. 880Rs. 4195', 'Rs. 2279Rs. 3799', 'Rs. 2749Rs. 5499', 'Rs. 1399Rs. 1699', 'Rs. 2249Rs. 2999', 'Rs. 1169Rs. 4330', 'Rs. 5224Rs. 5499', 'Rs. 2239Rs. 5599', 'Rs. 2039Rs. 3399', 'Rs. 899Rs. 4495', 'Rs. 2039Rs. 6799', 'Rs. 987Rs. 2599', 'Rs. 910Rs. 3795', 'Rs. 1799Rs. 2999', 'Rs. 2274Rs. 3499', 'Rs. 2699Rs. 3699', 'Rs. 789Rs. 2819', 'Rs. 3224Rs. 4299', 'Rs. 1169Rs. 4330', 'Rs. 2249Rs. 2999', 'Rs. 1589Rs. 5299', 'Rs. 1999Rs. 3999', 'Rs. 679Rs. 3999', 'Rs. 1919Rs. 6399', 'Rs. 779Rs. 1299', 'Rs. 2159Rs. 2999', 'Rs. 1999', 'Rs. 879Rs. 2199', 'Rs. 3399Rs. 3999', 'Rs. 899Rs. 4499', 'Rs. 1879Rs. 4699', 'Rs. 1399Rs. 1699', 'Rs. 1082Rs. 4330', 'Rs. 1259Rs. 2799', 'Rs. 1999Rs. 3599', 'Rs. 899Rs. 4495', 'Rs. 2159Rs. 3599', 'Rs. 7499', 'Rs. 1999Rs. 3999', 'Rs. 1529Rs. 5099', 'Rs. 1599Rs. 3999']\n"
     ]
    }
   ],
   "source": [
    "brand=[]\n",
    "s_s_desc=[]\n",
    "price=[]\n",
    "b_name=driver.find_elements(By.XPATH,\"//h3[@class='product-brand']\")\n",
    "desc=driver.find_elements(By.XPATH,\"//h4[@class='product-product']\")\n",
    "pr=driver.find_elements(By.XPATH,\"//div[@class='product-price']/span[1]\")\n",
    "#Using for loop with len function to iterate equal data\n",
    "for j in range(len(desc)):\n",
    "    brand.append(b_name[j].text)\n",
    "    s_s_desc.append(desc[j].text)\n",
    "    price.append(pr[j].text)\n",
    "print(brand)\n",
    "print(s_s_desc)\n",
    "print(price)\n",
    "\n",
    "#Clicking Next Button to reach next page to extract data\n",
    "n_button=driver.find_element(By.XPATH,\"//li[@class='pagination-next']/a\")\n",
    "n_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "995fb5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "brand1=[]\n",
    "s_s_desc1=[]\n",
    "price1=[]\n",
    "br_name=driver.find_elements(By.XPATH,\"//h3[@class='product-brand']\")\n",
    "desc1=driver.find_elements(By.XPATH,\"//h4[@class='product-product']\")\n",
    "pr1=driver.find_elements(By.XPATH,\"//div[@class='product-price']/span[1]\")\n",
    "for j in range(len(br_name)):\n",
    "    brand1.append(br_name[j].text)\n",
    "    s_s_desc1.append(desc1[j].text)\n",
    "    price1.append(pr1[j].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f688e8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "brands=brand+brand1\n",
    "s_s_describe=s_s_desc+s_s_desc1\n",
    "prices=price+price1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "610e3c65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Short Shoe Description</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Red Tape</td>\n",
       "      <td>Men Walking Shoes</td>\n",
       "      <td>Rs. 1559Rs. 5199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PUMA Motorsport</td>\n",
       "      <td>Men AMG Petronas F1 Sneakers</td>\n",
       "      <td>Rs. 6399Rs. 7999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>El Paso</td>\n",
       "      <td>Woven Design Slip-On Sneakers</td>\n",
       "      <td>Rs. 799Rs. 3495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Roadster</td>\n",
       "      <td>Men Sneakers</td>\n",
       "      <td>Rs. 872Rs. 3795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HRX by Hrithik Roshan</td>\n",
       "      <td>Men Aqua Shoes</td>\n",
       "      <td>Rs. 1169Rs. 2599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Red Tape</td>\n",
       "      <td>Women Walking Shoes</td>\n",
       "      <td>Rs. 1529Rs. 5099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Puma</td>\n",
       "      <td>Men Shore Running Shoes</td>\n",
       "      <td>Rs. 2749Rs. 4999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Skechers</td>\n",
       "      <td>Men GO WALK - TERRA Shoes</td>\n",
       "      <td>Rs. 9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Killer</td>\n",
       "      <td>Men Perforations Sneakers</td>\n",
       "      <td>Rs. 799Rs. 3995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Harvard</td>\n",
       "      <td>Men Printed High-Top Sneakers</td>\n",
       "      <td>Rs. 1203Rs. 2799</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Brand         Short Shoe Description             Price\n",
       "0                Red Tape              Men Walking Shoes  Rs. 1559Rs. 5199\n",
       "1         PUMA Motorsport   Men AMG Petronas F1 Sneakers  Rs. 6399Rs. 7999\n",
       "2                 El Paso  Woven Design Slip-On Sneakers   Rs. 799Rs. 3495\n",
       "3                Roadster                   Men Sneakers   Rs. 872Rs. 3795\n",
       "4   HRX by Hrithik Roshan                 Men Aqua Shoes  Rs. 1169Rs. 2599\n",
       "..                    ...                            ...               ...\n",
       "95               Red Tape            Women Walking Shoes  Rs. 1529Rs. 5099\n",
       "96                   Puma        Men Shore Running Shoes  Rs. 2749Rs. 4999\n",
       "97               Skechers      Men GO WALK - TERRA Shoes          Rs. 9999\n",
       "98                 Killer      Men Perforations Sneakers   Rs. 799Rs. 3995\n",
       "99                Harvard  Men Printed High-Top Sneakers  Rs. 1203Rs. 2799\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#making DataFrame of the scrapped data\n",
    "df=pd.DataFrame(list(zip(brands[0:100],s_s_describe[0:100],prices[0:100])),columns=[\"Brand\",\"Short Shoe Description\",\"Price\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "15864398",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close(# setting CPU Type filter to “Intel Core i7” as required\n",
    "cpu_type=driver.find_element(By.XPATH,'/html/body/div[1]/div[2]/div[1]/div[2]/div/div[3]/span/div[1]/div/div/div[5]/div[1]/span')\n",
    "cpu_type.click())# setting CPU Type filter to “Intel Core i7” as required\n",
    "cpu_type=driver.find_element(By.XPATH,'/html/body/div[1]/div[2]/div[1]/div[2]/div/div[3]/span/div[1]/div/div/div[5]/div[1]/span')\n",
    "cpu_type.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7790cd5b",
   "metadata": {},
   "source": [
    "# Q8: Go to webpage https://www.amazon.in/\n",
    "Enter “Laptop” in the search field and then click the search icon. Then set CPU Type filter to “Intel Core i7” You have to scrape 3 attributesfor each laptop:\n",
    "\n",
    "Title\n",
    "Ratings\n",
    "Price# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "df6e22ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "22a99e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.amazon.in/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4b96cd9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# entering \"Laptop\" in search field\n",
    "search=driver.find_element(By.XPATH,'/html/body/div[1]/header/div/div[1]/div[2]/div/form/div[2]/div[1]/input')\n",
    "search.send_keys('Laptop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1f402498",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clicking on the search button\n",
    "search_button=driver.find_element(By.XPATH,'//div[@class=\"nav-search-submit nav-sprite\"]')\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b7ad157b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting CPU Type filter to “Intel Core i7” as required\n",
    "cpu_type=driver.find_element(By.XPATH,'/html/body/div[1]/div[2]/div[1]/div[2]/div/div[3]/span/div[1]/div/div/div[5]/div[1]/span')\n",
    "cpu_type.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e53233f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrapping product title from the webpage\n",
    "title=[]\n",
    "for i in driver.find_elements(By.XPATH,'//div[@class=\"a-section a-spacing-none puis-padding-right-small s-title-instructions-style\"]')[0:10]:\n",
    "    title.append(i.text)\n",
    "    \n",
    "# Scrapping product price from the webpage\n",
    "price=[]\n",
    "for j in driver.find_elements(By.XPATH,'//span[@class=\"a-price-whole\"]')[0:10]:\n",
    "    price.append(j.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f39c28b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sponsored\\nAcer Aspire 5 Gaming Intel Core i5 ...</td>\n",
       "      <td>38,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sponsored\\nAcer Extensa 15 Lightweight Laptop ...</td>\n",
       "      <td>42,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(Renewed) Dell Latitude E5470 Intel Core i5 6t...</td>\n",
       "      <td>37,999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ASUS Vivobook 15, 15.6\" (39.62 cm) FHD, AMD Du...</td>\n",
       "      <td>56,999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ASUS Vivobook 15, 15.6-inch (39.62 cms) FHD, A...</td>\n",
       "      <td>32,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ASUS VivoBook 15 (2021), 15.6-inch (39.62 cm) ...</td>\n",
       "      <td>21,495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Dell New Windows 11 Inspiron 3525 Laptop, Inte...</td>\n",
       "      <td>34,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Lenovo IdeaPad Slim 1 Intel Celeron N4020 4th ...</td>\n",
       "      <td>43,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Lenovo IdeaPad Slim 3 Intel Celeron N4020 4th ...</td>\n",
       "      <td>37,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Lenovo IdeaPad Slim 1 AMD Ryzen 3 3250U 15.6\" ...</td>\n",
       "      <td>41,999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title   Price\n",
       "0  Sponsored\\nAcer Aspire 5 Gaming Intel Core i5 ...  38,990\n",
       "1  Sponsored\\nAcer Extensa 15 Lightweight Laptop ...  42,990\n",
       "2  (Renewed) Dell Latitude E5470 Intel Core i5 6t...  37,999\n",
       "3  ASUS Vivobook 15, 15.6\" (39.62 cm) FHD, AMD Du...  56,999\n",
       "4  ASUS Vivobook 15, 15.6-inch (39.62 cms) FHD, A...  32,990\n",
       "5  ASUS VivoBook 15 (2021), 15.6-inch (39.62 cm) ...  21,495\n",
       "6  Dell New Windows 11 Inspiron 3525 Laptop, Inte...  34,990\n",
       "7  Lenovo IdeaPad Slim 1 Intel Celeron N4020 4th ...  43,990\n",
       "8  Lenovo IdeaPad Slim 3 Intel Celeron N4020 4th ...  37,990\n",
       "9  Lenovo IdeaPad Slim 1 AMD Ryzen 3 3250U 15.6\" ...  41,999"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Laptop=pd.DataFrame({'Title':title,'Price':price}) \n",
    "Laptop.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8628a4",
   "metadata": {},
   "source": [
    "# Q9: Write a python program to scrape data for first 10 job results for Data Scientist Designation in Noida location.\n",
    "You have to scrape company name, No. of days ago when job was posted, Rating of the company."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "db64626b",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a4e0fd47",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.ambitionbox.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f6c5cc64",
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs=driver.find_element(By.XPATH,'/html/body/div/div/div/div[1]/header/nav/ul/li[5]/a')\n",
    "jobs.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "0ad4292e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#entering \"Data Scientist\" in \"Skill, Designation, Companies\" field\n",
    "search=driver.find_element(By.XPATH,'/html/body/div/div/div/div[2]/div[1]/div[1]/div/div/div/div/span/input')\n",
    "search.send_keys('Data Scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c88b182d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clicking on location icon\n",
    "location=driver.find_element(By.XPATH,'/html/body/div/div/div/div[2]/div[1]/div[2]/div[1]/div/div/div/div[2]/div[1]/p')\n",
    "location.click()\n",
    "\n",
    "# entering \"Noida\" for location search\n",
    "place=driver.find_element(By.XPATH,'/html/body/div/div/div/div[2]/div[1]/div[2]/div[1]/div/div/div/div[2]/div[2]/div/div[2]/input')\n",
    "place.send_keys('Noida')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "36664100",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.XPATH,'/html/body/div/div/div/div[2]/div[1]/div[2]/div[1]/div/div/div/div[2]/div[2]/div/div[3]/div[1]/div[1]/div/label')\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e90fd141",
   "metadata": {},
   "outputs": [],
   "source": [
    "company=[]\n",
    "for i in driver.find_elements(By.XPATH,'//p[@class=\"company body-medium\"]'): #scrapping company name from page\n",
    "    company.append(i.text)\n",
    "\n",
    "# Scrapping No. of days ago when job was posted from the webpage\n",
    "day=[]\n",
    "for j in driver.find_elements(By.XPATH,'//span[@class=\"body-small-l\"]'):\n",
    "    day.append(j.text)\n",
    "del day[1:20:2] \n",
    "    \n",
    "# Scrapping Rating of the Company from the webpage\n",
    "rating=[]\n",
    "for k in driver.find_elements(By.XPATH,'//span[@class=\"body-small\"]'):\n",
    "    rating.append(k.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "2e42f815",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company Name</th>\n",
       "      <th>No. of Days ago when job was posted</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Company Name No. of Days ago when job was posted Rating\n",
       "0                                                        \n",
       "1                                                        \n",
       "2                                                        \n",
       "3                                                        \n",
       "4                                                        \n",
       "5                                                        \n",
       "6                                                        \n",
       "7                                                        \n",
       "8                                                        \n",
       "9                                                        "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Jobs=pd.DataFrame({'Company Name':company, 'No. of Days ago when job was posted':day, 'Rating':rating})\n",
    "Jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ce3804",
   "metadata": {},
   "source": [
    "# Q10: Write a python program to scrape the salary data for Data Scientist designation.\n",
    "You have to scrape Company name, Number of salaries, Average salary, Minsalary, Max Salary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "f4d8bdb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "4ccc936e",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.ambitionbox.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "fb8c7c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting salary option\n",
    "salary=driver.find_element(By.XPATH,'/html/body/div/div/div/div[1]/header/nav/ul/li[3]/span')\n",
    "salary.click()\n",
    "\n",
    "# selecting first option from drop down menu\n",
    "browser=driver.find_element(By.XPATH,'/html/body/div/div/div/div[1]/header/nav/ul/li[3]/div/ul/li[1]/div/div[1]/img')\n",
    "browser.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "f44414f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# enterring 'Data Scientist' in Search job profile\n",
    "job=driver.find_element(By.XPATH,'//input[@class=\"tt-input\"]')\n",
    "job.send_keys('Data Scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "5ad96ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting first option from drop down menu\n",
    "select=driver.find_element(By.XPATH,'/html/body/div/div/div/main/section[1]/div[2]/div[1]/span/div/div/div[1]/div/div')\n",
    "select.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "5e0a9473",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrapping company name from the webpage\n",
    "comp=[]\n",
    "for i in driver.find_elements(By.XPATH,'//div[@class=\"company-info\"]/a'):\n",
    "    comp.append(i.text.split(\"\\n\"))\n",
    "    \n",
    "# merging sub lists into a single list and deleting even place items to get required data\n",
    "company=sum(comp,[])\n",
    "del company[1:20:2]\n",
    "\n",
    "# Scrapping total salary record from the webpage\n",
    "bsal=[]\n",
    "for a in driver.find_elements(By.XPATH,'//div[@class=\"sbold-list-header\"]/span'):\n",
    "    bsal.append(a.text.replace('(','').replace(')',''))\n",
    "\n",
    "# Scrapping Average salary from the webpage\n",
    "avgsal=[]\n",
    "for b in driver.find_elements(By.XPATH,'//p[@class=\"averageCtc\"]'): \n",
    "    avgsal.append(b.text)\n",
    "\n",
    "# Scrapping Minimum Salary & Maximum Salary from the webpage\n",
    "min_sal=[]\n",
    "max_sal=[]\n",
    "for c in driver.find_elements(By.XPATH,'//div[@class=\"value body-medium\"]'): \n",
    "    min_sal.append(c.text)\n",
    "    max_sal.append(c.text)\n",
    "del min_sal[1:20:2]\n",
    "del max_sal[0:20:2]\n",
    "\n",
    "# Scrapping Experience required data from the webpage\n",
    "exp=[]\n",
    "for d in driver.find_elements(By.XPATH,'//div[@class=\"sbold-list-header\"]'): \n",
    "    exp.append(d.text.split('('))\n",
    "    \n",
    "# merging sub lists into a single list and deleting even place items to get required data   \n",
    "req_exp=sum(exp,[]) \n",
    "del req_exp[1:20:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "e3e3d6fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Total Salary Record</th>\n",
       "      <th>Average Salary</th>\n",
       "      <th>Minimum Salary</th>\n",
       "      <th>Maximum Salary</th>\n",
       "      <th>Experience Required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Walmart</td>\n",
       "      <td>based on 24 salaries</td>\n",
       "      <td>₹ 32.2L</td>\n",
       "      <td>₹ 25.0L</td>\n",
       "      <td>₹ 45.0L</td>\n",
       "      <td>3-4 yrs experience</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ab Inbev</td>\n",
       "      <td>based on 59 salaries</td>\n",
       "      <td>₹ 19.8L</td>\n",
       "      <td>₹ 15.0L</td>\n",
       "      <td>₹ 26.0L</td>\n",
       "      <td>2-4 yrs experience</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Optum</td>\n",
       "      <td>based on 49 salaries</td>\n",
       "      <td>₹ 16.4L</td>\n",
       "      <td>₹ 11.0L</td>\n",
       "      <td>₹ 22.6L</td>\n",
       "      <td>2-4 yrs experience</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ZS</td>\n",
       "      <td>based on 35 salaries</td>\n",
       "      <td>₹ 15.9L</td>\n",
       "      <td>₹ 11.0L</td>\n",
       "      <td>₹ 22.0L</td>\n",
       "      <td>1-2 yrs experience</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fractal Analytics</td>\n",
       "      <td>based on 118 salaries</td>\n",
       "      <td>₹ 15.5L</td>\n",
       "      <td>₹ 9.0L</td>\n",
       "      <td>₹ 23.0L</td>\n",
       "      <td>2-4 yrs experience</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Sigmoid Analytics</td>\n",
       "      <td>based on 10 salaries</td>\n",
       "      <td>₹ 14.7L</td>\n",
       "      <td>₹ 12.7L</td>\n",
       "      <td>₹ 19.7L</td>\n",
       "      <td>1 yr experience</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Tiger Analytics</td>\n",
       "      <td>based on 70 salaries</td>\n",
       "      <td>₹ 14.6L</td>\n",
       "      <td>₹ 9.0L</td>\n",
       "      <td>₹ 20.0L</td>\n",
       "      <td>2-4 yrs experience</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Legato Health Technologies</td>\n",
       "      <td>based on 11 salaries</td>\n",
       "      <td>₹ 14.5L</td>\n",
       "      <td>₹ 11.0L</td>\n",
       "      <td>₹ 20.0L</td>\n",
       "      <td>4 yrs experience</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>HSBC</td>\n",
       "      <td>based on 10 salaries</td>\n",
       "      <td>₹ 14.0L</td>\n",
       "      <td>₹ 12.0L</td>\n",
       "      <td>₹ 18.0L</td>\n",
       "      <td>4 yrs experience</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Tredence</td>\n",
       "      <td>based on 14 salaries</td>\n",
       "      <td>₹ 13.9L</td>\n",
       "      <td>₹ 8.8L</td>\n",
       "      <td>₹ 17.5L</td>\n",
       "      <td>3 yrs experience</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Company Name    Total Salary Record Average Salary  \\\n",
       "0                     Walmart   based on 24 salaries        ₹ 32.2L   \n",
       "1                    Ab Inbev   based on 59 salaries        ₹ 19.8L   \n",
       "2                       Optum   based on 49 salaries        ₹ 16.4L   \n",
       "3                          ZS   based on 35 salaries        ₹ 15.9L   \n",
       "4           Fractal Analytics  based on 118 salaries        ₹ 15.5L   \n",
       "5           Sigmoid Analytics   based on 10 salaries        ₹ 14.7L   \n",
       "6             Tiger Analytics   based on 70 salaries        ₹ 14.6L   \n",
       "7  Legato Health Technologies   based on 11 salaries        ₹ 14.5L   \n",
       "8                        HSBC   based on 10 salaries        ₹ 14.0L   \n",
       "9                    Tredence   based on 14 salaries        ₹ 13.9L   \n",
       "\n",
       "  Minimum Salary Maximum Salary  Experience Required  \n",
       "0        ₹ 25.0L        ₹ 45.0L  3-4 yrs experience   \n",
       "1        ₹ 15.0L        ₹ 26.0L  2-4 yrs experience   \n",
       "2        ₹ 11.0L        ₹ 22.6L  2-4 yrs experience   \n",
       "3        ₹ 11.0L        ₹ 22.0L  1-2 yrs experience   \n",
       "4         ₹ 9.0L        ₹ 23.0L  2-4 yrs experience   \n",
       "5        ₹ 12.7L        ₹ 19.7L     1 yr experience   \n",
       "6         ₹ 9.0L        ₹ 20.0L  2-4 yrs experience   \n",
       "7        ₹ 11.0L        ₹ 20.0L    4 yrs experience   \n",
       "8        ₹ 12.0L        ₹ 18.0L    4 yrs experience   \n",
       "9         ₹ 8.8L        ₹ 17.5L    3 yrs experience   "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({'Company Name':company,'Total Salary Record':bsal,'Average Salary':avgsal,'Minimum Salary':min_sal,'Maximum Salary':max_sal,'Experience Required':req_exp})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "b9055e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f422cb8e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
