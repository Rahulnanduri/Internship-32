{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a902a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "import selenium\n",
    "import pandas as pd\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Importing selenium webdriver \n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Importing required Exceptions which needs to handled\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "#Importing requests\n",
    "import requests\n",
    "\n",
    "# importing regex\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "063c734a",
   "metadata": {},
   "source": [
    "# Q1. Write a python program which searches all the product under a particular product from www.amazon.in. The product to be searched will be taken as input from user. For e.g. If user input is ‘guitar’. Then search for guitars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1cb08aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the title of Product you are interest in search :guitar\n"
     ]
    }
   ],
   "source": [
    "#command to run chrome\n",
    "driver = webdriver.Chrome(r'chromedriver.exe')\n",
    "\n",
    "#get driver to visit defined URL\n",
    "driver.get('https://amazon.in')\n",
    "time.sleep(2)\n",
    "\n",
    "# Taking input from user about product search\n",
    "User_input=input('Enter the title of Product you are interest in search :')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d8859e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#input command in search bar\n",
    "search=driver.find_element(By.XPATH,'/html/body/div[1]/header/div/div[1]/div[2]/div/form/div[2]/div[1]/input')\n",
    "\n",
    "#clearing any previous input in search bar\n",
    "search.clear()\n",
    "\n",
    "#feeding input specified by user to search menu through send keys\n",
    "search.send_keys(User_input)\n",
    "\n",
    "#finding Search button for clicking through xpath\n",
    "search_button=driver.find_element(By.XPATH,'//div[@class=\"nav-search-submit nav-sprite\"]')\n",
    "\n",
    "#clicking search button\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec701ae4",
   "metadata": {},
   "source": [
    "# Q2. In the above question, now scrape the following details of each product listed in first 3 pages of your search results and save it in a data frame and csv. In case if any product has less than 3 pages in search results then scrape all the products available under that product name. Details to be scraped are: \"Brand Name\", \"Name of the Product\", \"Price\", \"Return/Exchange\", \"Expected Delivery\", \"Availability\" and “Product URL”. In case, if any of the details are missing for any of the product then replace it by “-“."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b0cba0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "b_name=[]\n",
    "product_name=[]\n",
    "rating=[]\n",
    "no_of_rating=[]\n",
    "price=[]\n",
    "ret_exchange=[]\n",
    "exp_delivery=[]\n",
    "availability=[]\n",
    "other_details=[]\n",
    "product_url=[]\n",
    "urls=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38375177",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,3):\n",
    "    if i>2:\n",
    "        break\n",
    "    p_urls=driver.find_elements(By.XPATH,'//a[@class=\"a-link-normal s-underline-text s-underline-link-text s-link-style a-text-normal\"]')\n",
    "    for i in p_urls:\n",
    "        urls.append(i.get_attribute('href'))\n",
    "\n",
    "\n",
    "    for i in urls:\n",
    "        driver.get(i)\n",
    "        time.sleep(2)\n",
    "    #scraping data for brand name\n",
    "        try:\n",
    "            bran=driver.find_element(By.XPATH,\"//a[@id='bylineInfo']\")\n",
    "            b_name.append(bran.text)\n",
    "        except NoSuchElementException as e:\n",
    "            b_name.append(\"--\")\n",
    "\n",
    "        #scraping data for product name\n",
    "        try:\n",
    "            prod=driver.find_element(By.XPATH,\"//h1[@id='title']/span\")\n",
    "            product_name.append(prod.text)\n",
    "        except NoSuchElementException as e:\n",
    "            product_name.append(\"--\")\n",
    "\n",
    "        #scraping data for rating\n",
    "        try:\n",
    "            rat=driver.find_element(By.XPATH,\"//span[@id='acrPopover']/span/a/i/span\")\n",
    "            rating.append(rat.text)\n",
    "        except NoSuchElementException as e:\n",
    "            rating.append(\"--\")\n",
    "            #scraping data for rating no.\n",
    "        try:\n",
    "            rat_no=driver.find_element(By.XPATH,\"//span[@id='acrCustomerReviewText']\")\n",
    "            no_of_rating.append(rat_no.text)\n",
    "        except NoSuchElementException as e:\n",
    "            no_of_rating.append(\"--\")\n",
    "\n",
    "        #scraping data for price\n",
    "        try:\n",
    "            pri=driver.find_element(By.XPATH,\"//div[@id='apex_desktop']/div/div/table/tbody/tr[2]/td[2]/span/span[2]\")\n",
    "            price.append(pri.text)\n",
    "        except NoSuchElementException as e:\n",
    "            price.append(\"--\")\n",
    "\n",
    "            #scaping data for return\n",
    "        try:\n",
    "            retu=driver.find_element(By.XPATH,\"//div[@id='RETURNS_POLICY']/span/div[2]/a\")\n",
    "            ret_exchange.append(retu.text)\n",
    "        except NoSuchElementException as e:\n",
    "            ret_exchange.append(\"--\")\n",
    "\n",
    "        #scraping data for expected delivery\n",
    "        try:\n",
    "            deliv=driver.find_element(By.XPATH,\"//div[@id='ddmDeliveryMessage']/b\")\n",
    "            exp_delivery.append(deliv.text)\n",
    "        except NoSuchElementException as e:\n",
    "            exp_delivery.append(\"--\")\n",
    "\n",
    "        #scraping data for availability\n",
    "        try:\n",
    "            avail=driver.find_element(By.XPATH,\"//div[@id='availability']/span\")\n",
    "            availability.append(avail.text)\n",
    "        except NoSuchElementException as e:\n",
    "            availability.append(\"--\")\n",
    "\n",
    "        #scraping data for other details\n",
    "        try:\n",
    "            od=driver.find_element(By.XPATH,\"//div[@id='feature-bullets']/ul/li/span\")\n",
    "            other_details.append(od.text)\n",
    "        except NoSuchElementException as e:\n",
    "            other_details.append(\"--\")# selecting and clicking next page\n",
    "    try:\n",
    "        if i==1:\n",
    "            n_button=driver.find_element(By.XPATH,\"//div[@class='a-section a-spacing-none a-padding-base']/div/ul/li[3]/a\")\n",
    "            n_url=n_button.get_attribute('href')\n",
    "            driver.get(n_url)\n",
    "            time.sleep(2)\n",
    "    except:\n",
    "        if i==2:\n",
    "            n_button=driver.find_element(By.XPATH,\"//div[@class='a-section a-spacing-none a-padding-base']/div/ul/li[4]/a\")\n",
    "            n_url=n_button.get_attribute('href')\n",
    "            driver.get(n_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09411c5",
   "metadata": {},
   "source": [
    "# Q3. Write a python program to access the search bar and search button on images.google.com and scrape 10 images each for keywords ‘fruits’, ‘cars’ and ‘Machine Learning’, ‘Guitar’, ‘Cakes’."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e5f7a5b",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (Temp/ipykernel_7632/170804736.py, line 36)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\BALLBU~1\\AppData\\Local\\Temp/ipykernel_7632/170804736.py\"\u001b[1;36m, line \u001b[1;32m36\u001b[0m\n\u001b[1;33m    urls.append(i)for i in range(len(urls)):\u001b[0m\n\u001b[1;37m                  ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#command to run chrome\n",
    "driver = webdriver.Chrome(r'chromedriver.exe')\n",
    "# Getting the webpage of mentioned url \n",
    "url = \"https://images.google.com/\"\n",
    "\n",
    "#Creating empty list \n",
    "urls = []   \n",
    "data = []    \n",
    "search_item = [\"fruits\", \"cars\", \"Machine Learning\", \"Guitar\", \"Cakes\"]\n",
    "for item in search_item:\n",
    "    driver.get(url)  \n",
    "    time.sleep(5)\n",
    "    \n",
    "    # Finding webelement for search_bar\n",
    "    search_bar = driver.find_element(By.TAG_NAME,\"input\") \n",
    "    \n",
    "    # Sending keys to get the keyword for search bar\n",
    "    search_bar.send_keys(str(item))\n",
    "    \n",
    "    # Clicking on search button\n",
    "    search_button = driver.find_element(By.XPATH,'//button[@class=\"Tg7LZd\"]').click()\n",
    "    \n",
    "    # Scrolling down the webpage to get some more images\n",
    "    for _ in range(50):\n",
    "        driver.execute_script(\"window.scrollBy(0,100)\")\n",
    "        \n",
    "        imgs = driver.find_elements(By.XPATH,'//img[@class=\"rg_i Q4LuWd\"]')\n",
    "    img_url = []\n",
    "    for image in imgs:\n",
    "        source = image.get_attribute('src')\n",
    "        if source is not None:\n",
    "                if(source[0:4] == 'http'):\n",
    "                    img_url.append(source)\n",
    "                    \n",
    "    for i in img_url[:10]:\n",
    "        urls.append(i)for i in range(len(urls)):\n",
    "    if i >= 50:\n",
    "        break\n",
    "    print(\"Downloading {0} of {1} images\" .format(i, 50))\n",
    "    response = requests.get(urls[i])\n",
    "    file = open(r\"Downloads\\fliprobo googlepics\"+str(i)+\".jpg\",\"wb\")\n",
    "    file.write(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf75755b",
   "metadata": {},
   "source": [
    "# Q4. Write a python program to search for a smartphone(e.g.: Oneplus Nord, pixel 4A, etc.) on www.flipkart.com and scrape following details for all the search results displayed on 1st page."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da211b3",
   "metadata": {},
   "source": [
    "Details to be scraped: “Brand Name”, “Smartphone name”, “Colour”, “RAM”, “Storage(ROM)”, “Primary Camera”, “Secondary Camera”, “Display Size”, “Battery Capacity”, “Price”, “Product URL”. Incase if any of the details is missing then replace it by “- “. Save your results in a dataframe and CSV.D\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b28bc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(r\"chromedriver.exe\")\n",
    "\n",
    "url = \"https://www.flipkart.com/\"\n",
    "driver.get(url)\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e38ecbb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element(By.XPATH,\"//button[@class='_2KpZ6l _2doB4z']\").click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f21bafdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Enter the name of Smartphone that has to be searched : oneplus nord\n"
     ]
    }
   ],
   "source": [
    "# to enter the item name which user wants to search\n",
    "item = input(\" Enter the name of Smartphone that has to be searched : \")\n",
    "\n",
    "#giving input key word to search bar\n",
    "serch_bar = driver.find_element(By.XPATH,\"//div[@class='_3OO5Xc']//input\")\n",
    "serch_bar.send_keys(item)\n",
    "\n",
    "# to click search button\n",
    "srch_btn = driver.find_element(By.XPATH,\"/html/body/div[1]/div/div[1]/div[1]/div[2]/div[2]/form/div/button\")\n",
    "srch_btn.click()\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be470e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "page1_urls = []\n",
    "urls = driver.find_elements(By.XPATH,'//a[@class=\"_1fQZEK\"]')\n",
    "for url in urls:\n",
    "    page1_urls.append(url.get_attribute(\"href\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "574b62ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(page1_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "80090284",
   "metadata": {},
   "outputs": [],
   "source": [
    "Smartphones = {}\n",
    "Smartphones[\"Brand\"] = []\n",
    "Smartphones[\"Phone name\"] = []\n",
    "Smartphones[\"Colour\"] = []\n",
    "Smartphones[\"RAM\"] = []\n",
    "Smartphones[\"Storage(ROM)\"] = []\n",
    "Smartphones[\"Primary Camera\"] = []\n",
    "Smartphones[\"Display Size\"] = []\n",
    "Smartphones[\"Battery Capacity\"] = []\n",
    "Smartphones[\"Price\"] = []\n",
    "Smartphones[\"URL\"] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1b64a754",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping URL =  https://www.flipkart.com/oneplus-nord-ce-2-lite-5g-black-dusk-128-gb/p/itm853d95cf27843?pid=MOBGG6SGT5TVGSG6&lid=LSTMOBGG6SGT5TVGSG6EXWFNK&marketplace=FLIPKART&q=oneplus+nord&store=tyy%2F4io&srno=s_1_1&otracker=search&otracker1=search&fm=organic&iid=2377544f-4742-43e0-98ef-8e0085069c7c.MOBGG6SGT5TVGSG6.SEARCH&ppt=hp&ppn=homepage&ssid=ido6171h1s0000001667907597224&qH=e8b736bf4fa84421\n",
      "Scraping URL =  https://www.flipkart.com/oneplus-nord-2t-5g-gray-shadow-128-gb/p/itm97eda8b1a1566?pid=MOBGHHYHYSZZHAGR&lid=LSTMOBGHHYHYSZZHAGRO6ZU25&marketplace=FLIPKART&q=oneplus+nord&store=tyy%2F4io&srno=s_1_2&otracker=search&otracker1=search&fm=organic&iid=2377544f-4742-43e0-98ef-8e0085069c7c.MOBGHHYHYSZZHAGR.SEARCH&ppt=hp&ppn=homepage&ssid=ido6171h1s0000001667907597224&qH=e8b736bf4fa84421\n",
      "Scraping URL =  https://www.flipkart.com/oneplus-nord-2t-5g-gray-shadow-256-gb/p/itm97eda8b1a1566?pid=MOBGFX6GFUSXWRQN&lid=LSTMOBGFX6GFUSXWRQN4ECOT3&marketplace=FLIPKART&q=oneplus+nord&store=tyy%2F4io&srno=s_1_3&otracker=search&otracker1=search&fm=organic&iid=2377544f-4742-43e0-98ef-8e0085069c7c.MOBGFX6GFUSXWRQN.SEARCH&ppt=hp&ppn=homepage&ssid=ido6171h1s0000001667907597224&qH=e8b736bf4fa84421\n",
      "Scraping URL =  https://www.flipkart.com/oneplus-nord-2t-5g-jade-fog-256-gb/p/itm97eda8b1a1566?pid=MOBGFX6PB4EGYBW8&lid=LSTMOBGFX6PB4EGYBW8BPG7NH&marketplace=FLIPKART&q=oneplus+nord&store=tyy%2F4io&srno=s_1_4&otracker=search&otracker1=search&fm=organic&iid=2377544f-4742-43e0-98ef-8e0085069c7c.MOBGFX6PB4EGYBW8.SEARCH&ppt=hp&ppn=homepage&ssid=ido6171h1s0000001667907597224&qH=e8b736bf4fa84421\n",
      "Scraping URL =  https://www.flipkart.com/oneplus-nord-2t-5g-jade-fog-128-gb/p/itm97eda8b1a1566?pid=MOBGJMUHQV7XU4GH&lid=LSTMOBGJMUHQV7XU4GHRI3ADN&marketplace=FLIPKART&q=oneplus+nord&store=tyy%2F4io&srno=s_1_5&otracker=search&otracker1=search&fm=organic&iid=2377544f-4742-43e0-98ef-8e0085069c7c.MOBGJMUHQV7XU4GH.SEARCH&ppt=hp&ppn=homepage&ssid=ido6171h1s0000001667907597224&qH=e8b736bf4fa84421\n",
      "Scraping URL =  https://www.flipkart.com/oneplus-nord-ce-2-lite-5g-black-dusk-128-gb/p/itm7acae55b999e6?pid=MOBGDWF8GJTFAXVH&lid=LSTMOBGDWF8GJTFAXVHSZ1LDM&marketplace=FLIPKART&q=oneplus+nord&store=tyy%2F4io&srno=s_1_6&otracker=search&otracker1=search&fm=organic&iid=2377544f-4742-43e0-98ef-8e0085069c7c.MOBGDWF8GJTFAXVH.SEARCH&ppt=hp&ppn=homepage&ssid=ido6171h1s0000001667907597224&qH=e8b736bf4fa84421\n",
      "Scraping URL =  https://www.flipkart.com/oneplus-nord-ce-2-lite-5g-black-dusk-128-gb/p/itm7acae55b999e6?pid=MOBGJMUHBTHF8HPM&lid=LSTMOBGJMUHBTHF8HPM53F99J&marketplace=FLIPKART&q=oneplus+nord&store=tyy%2F4io&srno=s_1_7&otracker=search&otracker1=search&fm=organic&iid=2377544f-4742-43e0-98ef-8e0085069c7c.MOBGJMUHBTHF8HPM.SEARCH&ppt=hp&ppn=homepage&ssid=ido6171h1s0000001667907597224&qH=e8b736bf4fa84421\n",
      "Scraping URL =  https://www.flipkart.com/oneplus-nord-2t-5g-gray-shadow-256-gb/p/itm97eda8b1a1566?pid=MOBGHHYEMNFZGE4W&lid=LSTMOBGHHYEMNFZGE4W5R78CB&marketplace=FLIPKART&q=oneplus+nord&store=tyy%2F4io&srno=s_1_8&otracker=search&otracker1=search&fm=organic&iid=2377544f-4742-43e0-98ef-8e0085069c7c.MOBGHHYEMNFZGE4W.SEARCH&ppt=hp&ppn=homepage&ssid=ido6171h1s0000001667907597224&qH=e8b736bf4fa84421\n",
      "Scraping URL =  https://www.flipkart.com/oneplus-nord-2t-5g-jade-fog-256-gb/p/itm97eda8b1a1566?pid=MOBGJMUH3XAHRTFF&lid=LSTMOBGJMUH3XAHRTFF9FEBSK&marketplace=FLIPKART&q=oneplus+nord&store=tyy%2F4io&srno=s_1_9&otracker=search&otracker1=search&fm=organic&iid=2377544f-4742-43e0-98ef-8e0085069c7c.MOBGJMUH3XAHRTFF.SEARCH&ppt=hp&ppn=homepage&ssid=ido6171h1s0000001667907597224&qH=e8b736bf4fa84421\n",
      "Scraping URL =  https://www.flipkart.com/oneplus-nord-2t-5g-gray-shadow-256-gb/p/itm97eda8b1a1566?pid=MOBGJMUH8GJZPY97&lid=LSTMOBGJMUH8GJZPY970NRDTD&marketplace=FLIPKART&q=oneplus+nord&store=tyy%2F4io&srno=s_1_10&otracker=search&otracker1=search&fm=organic&iid=2377544f-4742-43e0-98ef-8e0085069c7c.MOBGJMUH8GJZPY97.SEARCH&ppt=hp&ppn=homepage&ssid=ido6171h1s0000001667907597224&qH=e8b736bf4fa84421\n",
      "Scraping URL =  https://www.flipkart.com/oneplus-nord-2t-5g-gray-shadow-128-gb/p/itm97eda8b1a1566?pid=MOBGJMUHBTGNRZXZ&lid=LSTMOBGJMUHBTGNRZXZX1CTT8&marketplace=FLIPKART&q=oneplus+nord&store=tyy%2F4io&srno=s_1_11&otracker=search&otracker1=search&fm=organic&iid=2377544f-4742-43e0-98ef-8e0085069c7c.MOBGJMUHBTGNRZXZ.SEARCH&ppt=hp&ppn=homepage&ssid=ido6171h1s0000001667907597224&qH=e8b736bf4fa84421\n",
      "Scraping URL =  https://www.flipkart.com/oneplus-nord-ce-2-lite-5g-blue-tide-128-gb/p/itm7acae55b999e6?pid=MOBGDWFJFBKYTEGP&lid=LSTMOBGDWFJFBKYTEGPLVVHJU&marketplace=FLIPKART&q=oneplus+nord&store=tyy%2F4io&srno=s_1_12&otracker=search&otracker1=search&fm=organic&iid=2377544f-4742-43e0-98ef-8e0085069c7c.MOBGDWFJFBKYTEGP.SEARCH&ppt=hp&ppn=homepage&ssid=ido6171h1s0000001667907597224&qH=e8b736bf4fa84421\n",
      "Scraping URL =  https://www.flipkart.com/oneplus-nord-ce-2-lite-5g-blue-tide-128-gb/p/itm7acae55b999e6?pid=MOBGJMUHHJE55ARU&lid=LSTMOBGJMUHHJE55ARUFC3QO4&marketplace=FLIPKART&q=oneplus+nord&store=tyy%2F4io&srno=s_1_13&otracker=search&otracker1=search&fm=organic&iid=2377544f-4742-43e0-98ef-8e0085069c7c.MOBGJMUHHJE55ARU.SEARCH&ppt=hp&ppn=homepage&ssid=ido6171h1s0000001667907597224&qH=e8b736bf4fa84421\n",
      "Scraping URL =  https://www.flipkart.com/oneplus-nord-ce2-lite-5g-blue-tide-128-gb/p/itmecb4707631d8d?pid=MOBGGA2BHMFSM8AG&lid=LSTMOBGGA2BHMFSM8AGTXLA3C&marketplace=FLIPKART&q=oneplus+nord&store=tyy%2F4io&srno=s_1_14&otracker=search&otracker1=search&fm=organic&iid=2377544f-4742-43e0-98ef-8e0085069c7c.MOBGGA2BHMFSM8AG.SEARCH&ppt=hp&ppn=homepage&ssid=ido6171h1s0000001667907597224&qH=e8b736bf4fa84421\n",
      "Scraping URL =  https://www.flipkart.com/oneplus-nord-2t-5g-gray-shadow-256-gb/p/itm97eda8b1a1566?pid=MOBGGCHFNMZDKZTV&lid=LSTMOBGGCHFNMZDKZTVX54GIS&marketplace=FLIPKART&q=oneplus+nord&store=tyy%2F4io&srno=s_1_15&otracker=search&otracker1=search&fm=organic&iid=2377544f-4742-43e0-98ef-8e0085069c7c.MOBGGCHFNMZDKZTV.SEARCH&ppt=hp&ppn=homepage&ssid=ido6171h1s0000001667907597224&qH=e8b736bf4fa84421\n",
      "Scraping URL =  https://www.flipkart.com/oneplus-nord-2t-5g-jade-fog-128-gb/p/itm97eda8b1a1566?pid=MOBGHHYZVXCMYDSR&lid=LSTMOBGHHYZVXCMYDSRPLVB5G&marketplace=FLIPKART&q=oneplus+nord&store=tyy%2F4io&srno=s_1_16&otracker=search&otracker1=search&fm=organic&iid=2377544f-4742-43e0-98ef-8e0085069c7c.MOBGHHYZVXCMYDSR.SEARCH&ppt=hp&ppn=homepage&ssid=ido6171h1s0000001667907597224&qH=e8b736bf4fa84421\n",
      "Scraping URL =  https://www.flipkart.com/oneplus-nord-ce-2-lite-5g-blue-tide-128-gb/p/itm7acae55b999e6?pid=MOBGHHXQCZQVEQDG&lid=LSTMOBGHHXQCZQVEQDGEUXCJT&marketplace=FLIPKART&q=oneplus+nord&store=tyy%2F4io&srno=s_1_17&otracker=search&otracker1=search&fm=organic&iid=2377544f-4742-43e0-98ef-8e0085069c7c.MOBGHHXQCZQVEQDG.SEARCH&ppt=hp&ppn=homepage&ssid=ido6171h1s0000001667907597224&qH=e8b736bf4fa84421\n",
      "Scraping URL =  https://www.flipkart.com/oneplus-nord-2t-5g-jade-fog-256-gb/p/itm97eda8b1a1566?pid=MOBGGA29UT2G9QW3&lid=LSTMOBGGA29UT2G9QW3FFVUMM&marketplace=FLIPKART&q=oneplus+nord&store=tyy%2F4io&srno=s_1_18&otracker=search&otracker1=search&fm=organic&iid=2377544f-4742-43e0-98ef-8e0085069c7c.MOBGGA29UT2G9QW3.SEARCH&ppt=hp&ppn=homepage&ssid=ido6171h1s0000001667907597224&qH=e8b736bf4fa84421\n",
      "Exception occured while moving to next page\n",
      "Scraping URL =  https://www.flipkart.com/oneplus-nord-2t-5g-jade-fog-256-gb/p/itm97eda8b1a1566?pid=MOBGHHYHNZBQBPZY&lid=LSTMOBGHHYHNZBQBPZYJANSVX&marketplace=FLIPKART&q=oneplus+nord&store=tyy%2F4io&srno=s_1_19&otracker=search&otracker1=search&fm=organic&iid=2377544f-4742-43e0-98ef-8e0085069c7c.MOBGHHYHNZBQBPZY.SEARCH&ppt=hp&ppn=homepage&ssid=ido6171h1s0000001667907597224&qH=e8b736bf4fa84421\n",
      "Scraping URL =  https://www.flipkart.com/oneplus-nord-ce-2-5g-gray-mirror-128-gb/p/itm2a9883679c57c?pid=MOBGHHZDYQHWEGMX&lid=LSTMOBGHHZDYQHWEGMXBPGZAF&marketplace=FLIPKART&q=oneplus+nord&store=tyy%2F4io&srno=s_1_20&otracker=search&otracker1=search&fm=organic&iid=2377544f-4742-43e0-98ef-8e0085069c7c.MOBGHHZDYQHWEGMX.SEARCH&ppt=hp&ppn=homepage&ssid=ido6171h1s0000001667907597224&qH=e8b736bf4fa84421\n",
      "Scraping URL =  https://www.flipkart.com/oneplus-nord-gray-onyx-128-gb/p/itm49f817b591982?pid=MOBFUE5HW4XUUGBN&lid=LSTMOBFUE5HW4XUUGBNMZB8TR&marketplace=FLIPKART&q=oneplus+nord&store=tyy%2F4io&srno=s_1_21&otracker=search&otracker1=search&fm=organic&iid=2377544f-4742-43e0-98ef-8e0085069c7c.MOBFUE5HW4XUUGBN.SEARCH&ppt=hp&ppn=homepage&ssid=ido6171h1s0000001667907597224&qH=e8b736bf4fa84421\n",
      "Scraping URL =  https://www.flipkart.com/oneplus-nord-gray-onyx-256-gb/p/itm49f817b591982?pid=MOBFUE5GGWHFC37J&lid=LSTMOBFUE5GGWHFC37JNXZLYZ&marketplace=FLIPKART&q=oneplus+nord&store=tyy%2F4io&srno=s_1_22&otracker=search&otracker1=search&fm=organic&iid=2377544f-4742-43e0-98ef-8e0085069c7c.MOBFUE5GGWHFC37J.SEARCH&ppt=hp&ppn=homepage&ssid=ido6171h1s0000001667907597224&qH=e8b736bf4fa84421\n",
      "Scraping URL =  https://www.flipkart.com/oneplus-nord-gray-onyx-64-gb/p/itm49f817b591982?pid=MOBFUE5H57THFNVJ&lid=LSTMOBFUE5H57THFNVJSYCAHJ&marketplace=FLIPKART&q=oneplus+nord&store=tyy%2F4io&srno=s_1_23&otracker=search&otracker1=search&fm=organic&iid=2377544f-4742-43e0-98ef-8e0085069c7c.MOBFUE5H57THFNVJ.SEARCH&ppt=hp&ppn=homepage&ssid=ido6171h1s0000001667907597224&qH=e8b736bf4fa84421\n",
      "Scraping URL =  https://www.flipkart.com/oneplus-nord-blue-marble-256-gb/p/itm49f817b591982?pid=MOBFUE5HUU5ZYGRY&lid=LSTMOBFUE5HUU5ZYGRY4ZWZZN&marketplace=FLIPKART&q=oneplus+nord&store=tyy%2F4io&srno=s_1_24&otracker=search&otracker1=search&fm=organic&iid=2377544f-4742-43e0-98ef-8e0085069c7c.MOBFUE5HUU5ZYGRY.SEARCH&ppt=hp&ppn=homepage&ssid=ido6171h1s0000001667907597224&qH=e8b736bf4fa84421\n"
     ]
    }
   ],
   "source": [
    "# Scraping data from each url of page 1\n",
    "for url in page1_urls:\n",
    "    driver.get(url)                                                        \n",
    "    print(\"Scraping URL = \", url)\n",
    "    Smartphones['URL'].append(url)                                                          \n",
    "    time.sleep(2)\n",
    "    \n",
    "    \n",
    "    #Clicking on read more button\n",
    "    try:\n",
    "        read_more = driver.find_element(By.XPATH,'//button[@class=\"_2KpZ6l _1FH0tX\"]')     \n",
    "        read_more.click()\n",
    "    except NoSuchElementException:\n",
    "        print(\"Exception occured while moving to next page\")\n",
    "    \n",
    "    \n",
    "    #Scraping brand name of phone data\n",
    "    try:\n",
    "        brand_tags = driver.find_element(By.XPATH,'//span[@class=\"B_NuCI\"]')      \n",
    "        Smartphones[\"Brand\"].append(brand_tags.text.split()[0])\n",
    "    except NoSuchElementException:\n",
    "        Smartphones['Brand'].append('-')\n",
    "    \n",
    "    \n",
    "    #Scraping phone name data\n",
    "    try:\n",
    "        name_tags = driver.find_element(By.XPATH,'//li[@class=\"_21lJbe\"]')     \n",
    "        Smartphones['Phone name'].append(name_tags.text)\n",
    "    except NoSuchElementException:\n",
    "        Smartphones['Phone name'].append('-')\n",
    "    \n",
    "    \n",
    "    #Scraping phone color data\n",
    "    try:\n",
    "        color_tags = driver.find_element(By.XPATH,'//div[@class=\"_3k-BhJ\"][1]/table/tbody/tr[4]/td[2]/ul/li')      \n",
    "        Smartphones['Colour'].append(color_tags.text)\n",
    "    except NoSuchElementException:\n",
    "        Smartphones['Colour'].append('-')\n",
    "            \n",
    "      #Scraping RAM data\n",
    "    try:\n",
    "        ram_tags = driver.find_element(By.XPATH,'//div[@class=\"_3k-BhJ\"][4]/table[1]/tbody/tr[2]/td[2]/ul/li')                \n",
    "        Smartphones['RAM'].append(ram_tags.text)\n",
    "    except NoSuchElementException:\n",
    "        Smartphones['RAM'].append('-')\n",
    "    \n",
    "    \n",
    "    #Scraping ROM data\n",
    "    try:\n",
    "        rom_tags = driver.find_element(By.XPATH,'//div[@class=\"_3k-BhJ\"][4]/table[1]/tbody/tr[1]/td[2]/ul/li')        \n",
    "        Smartphones['Storage(ROM)'].append(rom_tags.text)\n",
    "    except NoSuchElementException:\n",
    "        Smartphones['Storage(ROM)'].append('-')\n",
    "        \n",
    "            \n",
    "    #Scraping Primary camera data\n",
    "    try:                                                                                    \n",
    "        pri_tags = driver.find_element(By.XPATH,'//div[@class=\"_3k-BhJ\"][5]/table[1]/tbody/tr[2]/td[2]/ul/li')\n",
    "        Smartphones['Primary Camera'].append(pri_tags.text)\n",
    "    except NoSuchElementException:\n",
    "        Smartphones['Primary Camera'].append('-')\n",
    "        \n",
    "   \n",
    "    #Scraping Display size data \n",
    "    try:\n",
    "        disp_tags = driver.find_element(By.XPATH,'//div[@class=\"_3k-BhJ\"][2]/div')\n",
    "        if disp_tags.text != \"Display Features\" : raise NoSuchElementException\n",
    "        disp_size = driver.find_element(By.XPATH,'//div[@class=\"_3k-BhJ\"][2]/table[1]/tbody/tr[1]/td[2]/ul/li')  \n",
    "        Smartphones['Display Size'].append(disp_size.text)\n",
    "    except NoSuchElementException:\n",
    "        Smartphones['Display Size'].append('-')\n",
    "         \n",
    "    #Scraping battery capacity data\n",
    "    try:\n",
    "        if driver.find_element(By.XPATH,'//div[@class=\"_3k-BhJ\"][10]/div').text != \"Battery & Power Features\" :\n",
    "            if driver.find_element(By.XPATH,'//div[@class=\"_3k-BhJ\"][9]/div').text == \"Battery & Power Features\" :\n",
    "                bat_tags = driver.find_element(By.XPATH,'//div[@class=\"_3k-BhJ\"][9]/table/tbody/tr/td[1]')\n",
    "                if bat_tags.text != \"Battery Capacity\" : raise NoSuchElementException\n",
    "                bat_capa = driver.find_element(By.XPATH,'//div[@class=\"_3k-BhJ\"][9]/table/tbody/tr/td[2]/ul/li')                \n",
    "            elif driver.find_element_by_xpath('//div[@class=\"_3k-BhJ\"][8]/div').text == \"Battery & Power Features\" :\n",
    "                bat_tags = driver.find_element(By.XPATH,'//div[@class=\"_3k-BhJ\"][8]/table/tbody/tr/td[1]')\n",
    "                if bat_tags.text != \"Battery Capacity\" : raise NoSuchElementException\n",
    "                bat_capa = driver.find_element(By.XPATH,'//div[@class=\"_3k-BhJ\"][8]/table/tbody/tr/td[2]/ul/li')\n",
    "            else:\n",
    "                raise NoSuchElementException\n",
    "        else :\n",
    "            bat_tags = driver.find_element(By.XPATH,'//div[@class=\"_3k-BhJ\"][10]/table/tbody/tr/td[1]')\n",
    "            if bat_tags.text != \"Battery Capacity\" : raise NoSuchElementException\n",
    "            bat_capa = driver.find_element(By.XPATH,'//div[@class=\"_3k-BhJ\"][10]/table/tbody/tr/td[2]/ul/li')              \n",
    "        Smartphones['Battery Capacity'].append(bat_capa.text)\n",
    "    except NoSuchElementException:\n",
    "        Smartphones['Battery Capacity'].append('-')\n",
    "        \n",
    "         #Scraping Price data\n",
    "    try:\n",
    "        price_tags = driver.find_element(By.XPATH,'//div[@class=\"_30jeq3 _16Jk6d\"]')      \n",
    "        Smartphones['Price'].append(price_tags.text)\n",
    "    except NoSuchElementException:\n",
    "        Smartphones['Price'].append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "242b584c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24 24 24 24 24\n"
     ]
    }
   ],
   "source": [
    "print(len(Smartphones[\"Brand\"]), len(Smartphones[\"Phone name\"]), len(Smartphones[\"Colour\"]), len(Smartphones[\"RAM\"]), len(Smartphones[\"Storage(ROM)\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "12d29c13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method WebDriver.close of <selenium.webdriver.chrome.webdriver.WebDriver (session=\"96a055adfa0241353af4bf4e68b753a8\")>>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver.close"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ad18fb",
   "metadata": {},
   "source": [
    "# Q5. Write a program to scrap geospatial coordinates (latitude, longitude) of a city searched on google maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a4eb6ec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter City name that has to be searched : hyderabad\n",
      "URL Extracted:  https://www.google.co.in/maps/place/Hyderabad,+Telangana/@17.4121531,78.1278444,10z/data=!3m1!4b1!4m5!3m4!1s0x3bcb99daeaebd2c7:0xae93b78392bafbc2!8m2!3d17.385044!4d78.486671\n",
      "Latitude = 17.4121531, Longitude = 78.1278444\n"
     ]
    }
   ],
   "source": [
    "# to get web browser\n",
    "driver=webdriver.Chrome(r\"chromedriver.exe\") \n",
    "time.sleep(2)\n",
    "\n",
    "# opening google maps\n",
    "url = \"https://www.google.co.in/maps\"\n",
    "driver.get(url)\n",
    "time.sleep(2)\n",
    "\n",
    "\n",
    "#Sending keyword for seach bar and search button\n",
    "city = input('Enter City name that has to be searched : ')\n",
    "search_bar = driver.find_element(By.ID,\"searchboxinput\")                       \n",
    "search_bar.clear()                                                             \n",
    "time.sleep(2)\n",
    "search_bar.send_keys(city)                                                     \n",
    "search_btn = driver.find_element(By.ID,\"searchbox-searchbutton\")              \n",
    "search_btn.click()                                                             \n",
    "time.sleep(3)\n",
    "\n",
    "try:\n",
    "    url_string = driver.current_url\n",
    "    print(\"URL Extracted: \", url_string)\n",
    "    lat_lng = re.findall(r'@(.*)data',url_string)\n",
    "    if len(lat_lng):\n",
    "        lat_lng_list = lat_lng[0].split(\",\")\n",
    "        if len(lat_lng_list)>=2:\n",
    "            lat = lat_lng_list[0]\n",
    "            lng = lat_lng_list[1]\n",
    "        print(\"Latitude = {}, Longitude = {}\".format(lat, lng))\n",
    "\n",
    "except Exception as e:\n",
    "        print(\"Error: \", str(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6867ece0",
   "metadata": {},
   "source": [
    "# Q6. Write a program to scrap details of all the funding deals for second quarter (i.e Jan 21 – March 21) from trak.in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "24d8cb76",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"chromedriver.exe\") \n",
    "time.sleep(2)\n",
    "\n",
    "#to get url\n",
    "driver.get('https://trak.in/')\n",
    "\n",
    "#to get xpath for funding deals\n",
    "fund_button = driver.find_element(By.XPATH,'//li[@id=\"menu-item-51510\"]/a').get_attribute('href')\n",
    "driver.get(fund_button)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "093b8016",
   "metadata": {},
   "outputs": [],
   "source": [
    "fund_dict = {}\n",
    "fund_dict['Date'] = []\n",
    "fund_dict['Startup Name'] = []\n",
    "fund_dict['Industry/Vertical'] = []\n",
    "fund_dict['Sub-Vertical'] = []\n",
    "fund_dict['Location'] = []\n",
    "fund_dict['Investor'] = []\n",
    "fund_dict['Investment Type'] = []\n",
    "fund_dict['Amount(in USD)'] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "45c6e003",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(54,57):\n",
    "    # Date\n",
    "    dt = driver.find_elements(By.XPATH,'//table[@id=\"tablepress-{}\"]/tbody/tr/td[2]'.format(i))\n",
    "    for d in dt:\n",
    "        fund_dict['Date'].append(d.text)\n",
    "\n",
    "    # Startup Name\n",
    "    sn = driver.find_elements(By.XPATH,'//table[@id=\"tablepress-{}\"]/tbody/tr/td[3]'.format(i))\n",
    "    for n in sn:\n",
    "        fund_dict['Startup Name'].append(n.text)\n",
    "    \n",
    "    # Industry/Vertical\n",
    "    ind = driver.find_elements(By.XPATH,'//table[@id=\"tablepress-{}\"]/tbody/tr/td[4]'.format(i))\n",
    "    for n in ind:\n",
    "        fund_dict['Industry/Vertical'].append(n.text)\n",
    "    \n",
    "    # Sub-Vertical\n",
    "    sv = driver.find_elements(By.XPATH,'//table[@id=\"tablepress-{}\"]/tbody/tr/td[5]'.format(i))\n",
    "    for s in sv:\n",
    "        fund_dict['Sub-Vertical'].append(s.text)\n",
    "\n",
    "    # Location\n",
    "    loc = driver.find_elements(By.XPATH,'//table[@id=\"tablepress-{}\"]/tbody/tr/td[6]'.format(i))\n",
    "    for l in loc:\n",
    "        fund_dict['Location'].append(l.text)\n",
    "    \n",
    "      # Investor\n",
    "    inv = driver.find_elements(By.XPATH,'//table[@id=\"tablepress-{}\"]/tbody/tr/td[7]'.format(i))\n",
    "    for n in inv:\n",
    "        fund_dict['Investor'].append(n.text)\n",
    "    \n",
    "    # Investment Type\n",
    "    invt = driver.find_elements(By.XPATH,'//table[@id=\"tablepress-{}\"]/tbody/tr/td[8]'.format(i))\n",
    "    for n in invt:\n",
    "        fund_dict['Investment Type'].append(n.text)\n",
    "    \n",
    "    # Amount\n",
    "    amt = driver.find_elements(By.XPATH,'//table[@id=\"tablepress-{}\"]/tbody/tr/td[9]'.format(i))\n",
    "    for a in amt:\n",
    "        fund_dict['Amount(in USD)'].append(a.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3d497129",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Startup Name</th>\n",
       "      <th>Industry/Vertical</th>\n",
       "      <th>Sub-Vertical</th>\n",
       "      <th>Location</th>\n",
       "      <th>Investor</th>\n",
       "      <th>Investment Type</th>\n",
       "      <th>Amount(in USD)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15/01/2021</td>\n",
       "      <td>Digit Insurance</td>\n",
       "      <td>Financial Services</td>\n",
       "      <td>Insurance Services</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>A91 Partners, Faering Capital, TVS Capital Funds</td>\n",
       "      <td>Venture</td>\n",
       "      <td>1,80,00,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28/01/2021</td>\n",
       "      <td>Bombay Shaving Company</td>\n",
       "      <td>Consumer Goods Company</td>\n",
       "      <td>Shave care, beard care, and skincare products</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>Reckitt Benckiser</td>\n",
       "      <td>Venture</td>\n",
       "      <td>6,172,258.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19/01/2021</td>\n",
       "      <td>DeHaat</td>\n",
       "      <td>AgriTech Startup</td>\n",
       "      <td>online marketplace for farm products and services</td>\n",
       "      <td>Patna</td>\n",
       "      <td>Prosus Ventures</td>\n",
       "      <td>Series C</td>\n",
       "      <td>30,000,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19/01/2021</td>\n",
       "      <td>Darwinbox</td>\n",
       "      <td>SaaS</td>\n",
       "      <td>HR Tech</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Salesforce Ventures</td>\n",
       "      <td>Seed</td>\n",
       "      <td>15,000,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18/01/2021</td>\n",
       "      <td>mfine</td>\n",
       "      <td>Health Tech Startup</td>\n",
       "      <td>AI-powered telemedicine mobile app</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Heritas Capital Management</td>\n",
       "      <td>Venture Round</td>\n",
       "      <td>16,000,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>18/01/2021</td>\n",
       "      <td>Udayy</td>\n",
       "      <td>EdTech</td>\n",
       "      <td>Online learning platform for kids in class 1-5</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>Sequoia Capital</td>\n",
       "      <td>Seed Funding</td>\n",
       "      <td>15,000,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>11/01/2021</td>\n",
       "      <td>True Elements</td>\n",
       "      <td>Food Startup</td>\n",
       "      <td>Whole Food plant based Nashta</td>\n",
       "      <td>Pune</td>\n",
       "      <td>SIDBI Venture Capital</td>\n",
       "      <td>Series</td>\n",
       "      <td>100,000,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>13/01/2021</td>\n",
       "      <td>Saveo</td>\n",
       "      <td>B2B E-commerce</td>\n",
       "      <td>Pharmacies</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Matrix Partners India, RTP Global, others</td>\n",
       "      <td>Seed</td>\n",
       "      <td>4,000,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>11/02/2021</td>\n",
       "      <td>Doubtnut</td>\n",
       "      <td>Edu Tech</td>\n",
       "      <td>E-Learning Platform</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>SIG Global, Sequoia Capital, WaterBridge Ventu...</td>\n",
       "      <td>Series B</td>\n",
       "      <td>2,500,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>22/02/2021</td>\n",
       "      <td>Zomato</td>\n",
       "      <td>Hospitality</td>\n",
       "      <td>Online Food Delivery Platform</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>Tiger Global, Kora</td>\n",
       "      <td>Venture</td>\n",
       "      <td>250,000,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>19/02/2021</td>\n",
       "      <td>Fingerlix</td>\n",
       "      <td>Hospitality</td>\n",
       "      <td>Semi-cooked food delivery app</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Rhodium Trust, Accel Partners and Swiggy</td>\n",
       "      <td>Series C</td>\n",
       "      <td>2,747,045.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>17/02/2021</td>\n",
       "      <td>Zolve</td>\n",
       "      <td>FinTech</td>\n",
       "      <td>Global Neobank Venture</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Accel Partners and Lightspeed Venture Partners</td>\n",
       "      <td>Seed</td>\n",
       "      <td>1,50,00,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>15/02/2021</td>\n",
       "      <td>KreditBee</td>\n",
       "      <td>Finance</td>\n",
       "      <td>Digital lending platform</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Azim Premji’s PremjiInvest and South Korea’s M...</td>\n",
       "      <td>Series C</td>\n",
       "      <td>75,000,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>12/02/2021</td>\n",
       "      <td>Pepperfry</td>\n",
       "      <td>E-commerce</td>\n",
       "      <td>Multi-brand furniture brand</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>InnoVen Capital</td>\n",
       "      <td>Debt Financing</td>\n",
       "      <td>4,773,958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>12/02/2021</td>\n",
       "      <td>Grofers</td>\n",
       "      <td>E-Commerce</td>\n",
       "      <td>Online supermarket</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>SoftBank Vision Fund (SVF)</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>55,000,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>09/02/2021</td>\n",
       "      <td>Nothing</td>\n",
       "      <td>Technology</td>\n",
       "      <td>Consumer Technology Venture</td>\n",
       "      <td>London</td>\n",
       "      <td>GV</td>\n",
       "      <td>Series A</td>\n",
       "      <td>15,000,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>09/02/2021</td>\n",
       "      <td>SplashLearn</td>\n",
       "      <td>EdTech</td>\n",
       "      <td>Game-based learning programme</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>Owl Ventures</td>\n",
       "      <td>Series C</td>\n",
       "      <td>18,000,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>04/03/2021</td>\n",
       "      <td>DealShare</td>\n",
       "      <td>E-commerce</td>\n",
       "      <td>Online shopping platform</td>\n",
       "      <td>Jaipur, Rajasthan</td>\n",
       "      <td>Innoven Capital</td>\n",
       "      <td>Debt Financing</td>\n",
       "      <td>250,000,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>31/03/2021</td>\n",
       "      <td>Uniphore</td>\n",
       "      <td>Technology</td>\n",
       "      <td>Conversational Service Automation (CSA)</td>\n",
       "      <td>Palo Alto</td>\n",
       "      <td>Sorenson Capital Partners</td>\n",
       "      <td>Series D</td>\n",
       "      <td>140,000,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>30/03/2021</td>\n",
       "      <td>Dunzo</td>\n",
       "      <td>E-commerce</td>\n",
       "      <td>Hyper-local delivery app</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Krishtal Advisors Pte Ltd</td>\n",
       "      <td>Series E</td>\n",
       "      <td>8,000,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>30/03/2021</td>\n",
       "      <td>BYJU’S</td>\n",
       "      <td>Edu-tech</td>\n",
       "      <td>Online tutoring</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>MC Global Edtech, B Capital, Baron, others</td>\n",
       "      <td>Series F</td>\n",
       "      <td>460,000,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>23/03/2021</td>\n",
       "      <td>SkilloVilla</td>\n",
       "      <td>Edu-tech</td>\n",
       "      <td>Career and job-oriented upskilling.</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Titan Capital, others</td>\n",
       "      <td>Seed</td>\n",
       "      <td>300,000,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>25/03/2021</td>\n",
       "      <td>CityMall</td>\n",
       "      <td>E-commerce</td>\n",
       "      <td>Social ecommerce and online grocery platform</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>Accel Partners</td>\n",
       "      <td>Series A</td>\n",
       "      <td>11,000,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>26/03/2021</td>\n",
       "      <td>DotPe</td>\n",
       "      <td>FinTech</td>\n",
       "      <td>Commerce and payments platform to offline ente...</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>PayU</td>\n",
       "      <td>Series A</td>\n",
       "      <td>27,500,000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date            Startup Name       Industry/Vertical  \\\n",
       "0   15/01/2021         Digit Insurance      Financial Services   \n",
       "1   28/01/2021  Bombay Shaving Company  Consumer Goods Company   \n",
       "2   19/01/2021                  DeHaat        AgriTech Startup   \n",
       "3   19/01/2021               Darwinbox                    SaaS   \n",
       "4   18/01/2021                   mfine     Health Tech Startup   \n",
       "5   18/01/2021                   Udayy                  EdTech   \n",
       "6   11/01/2021           True Elements            Food Startup   \n",
       "7   13/01/2021                   Saveo          B2B E-commerce   \n",
       "8   11/02/2021                Doubtnut                Edu Tech   \n",
       "9   22/02/2021                  Zomato             Hospitality   \n",
       "10  19/02/2021               Fingerlix             Hospitality   \n",
       "11  17/02/2021                   Zolve                 FinTech   \n",
       "12  15/02/2021               KreditBee                 Finance   \n",
       "13  12/02/2021               Pepperfry              E-commerce   \n",
       "14  12/02/2021                 Grofers              E-Commerce   \n",
       "15  09/02/2021                 Nothing              Technology   \n",
       "16  09/02/2021             SplashLearn                  EdTech   \n",
       "17  04/03/2021               DealShare              E-commerce   \n",
       "18  31/03/2021                Uniphore              Technology   \n",
       "19  30/03/2021                   Dunzo              E-commerce   \n",
       "20  30/03/2021                  BYJU’S                Edu-tech   \n",
       "21  23/03/2021             SkilloVilla                Edu-tech   \n",
       "22  25/03/2021                CityMall              E-commerce   \n",
       "23  26/03/2021                   DotPe                 FinTech   \n",
       "\n",
       "                                         Sub-Vertical           Location  \\\n",
       "0                                  Insurance Services          Bengaluru   \n",
       "1       Shave care, beard care, and skincare products          New Delhi   \n",
       "2   online marketplace for farm products and services              Patna   \n",
       "3                                             HR Tech             Mumbai   \n",
       "4                  AI-powered telemedicine mobile app          Bengaluru   \n",
       "5      Online learning platform for kids in class 1-5            Gurgaon   \n",
       "6                       Whole Food plant based Nashta               Pune   \n",
       "7                                          Pharmacies          Bengaluru   \n",
       "8                                 E-Learning Platform            Gurgaon   \n",
       "9                       Online Food Delivery Platform            Gurgaon   \n",
       "10                      Semi-cooked food delivery app             Mumbai   \n",
       "11                             Global Neobank Venture             Mumbai   \n",
       "12                           Digital lending platform          Bengaluru   \n",
       "13                        Multi-brand furniture brand             Mumbai   \n",
       "14                                 Online supermarket            Gurgaon   \n",
       "15                        Consumer Technology Venture             London   \n",
       "16                      Game-based learning programme            Gurgaon   \n",
       "17                           Online shopping platform  Jaipur, Rajasthan   \n",
       "18            Conversational Service Automation (CSA)          Palo Alto   \n",
       "19                           Hyper-local delivery app          Bengaluru   \n",
       "20                                    Online tutoring          Bengaluru   \n",
       "21                Career and job-oriented upskilling.          Bengaluru   \n",
       "22       Social ecommerce and online grocery platform            Gurgaon   \n",
       "23  Commerce and payments platform to offline ente...            Gurgaon   \n",
       "\n",
       "                                             Investor Investment Type  \\\n",
       "0    A91 Partners, Faering Capital, TVS Capital Funds         Venture   \n",
       "1                                   Reckitt Benckiser         Venture   \n",
       "2                                     Prosus Ventures        Series C   \n",
       "3                                 Salesforce Ventures            Seed   \n",
       "4                          Heritas Capital Management   Venture Round   \n",
       "5                                     Sequoia Capital    Seed Funding   \n",
       "6                               SIDBI Venture Capital          Series   \n",
       "7           Matrix Partners India, RTP Global, others            Seed   \n",
       "8   SIG Global, Sequoia Capital, WaterBridge Ventu...        Series B   \n",
       "9                                  Tiger Global, Kora         Venture   \n",
       "10           Rhodium Trust, Accel Partners and Swiggy        Series C   \n",
       "11     Accel Partners and Lightspeed Venture Partners            Seed   \n",
       "12  Azim Premji’s PremjiInvest and South Korea’s M...        Series C   \n",
       "13                                    InnoVen Capital  Debt Financing   \n",
       "14                         SoftBank Vision Fund (SVF)     Unspecified   \n",
       "15                                                 GV        Series A   \n",
       "16                                       Owl Ventures        Series C   \n",
       "17                                    Innoven Capital  Debt Financing   \n",
       "18                          Sorenson Capital Partners        Series D   \n",
       "19                          Krishtal Advisors Pte Ltd        Series E   \n",
       "20         MC Global Edtech, B Capital, Baron, others        Series F   \n",
       "21                              Titan Capital, others            Seed   \n",
       "22                                     Accel Partners        Series A   \n",
       "23                                               PayU        Series A   \n",
       "\n",
       "   Amount(in USD)  \n",
       "0     1,80,00,000  \n",
       "1    6,172,258.50  \n",
       "2      30,000,000  \n",
       "3      15,000,000  \n",
       "4      16,000,000  \n",
       "5      15,000,000  \n",
       "6     100,000,000  \n",
       "7       4,000,000  \n",
       "8       2,500,000  \n",
       "9     250,000,000  \n",
       "10   2,747,045.20  \n",
       "11    1,50,00,000  \n",
       "12     75,000,000  \n",
       "13      4,773,958  \n",
       "14     55,000,000  \n",
       "15     15,000,000  \n",
       "16     18,000,000  \n",
       "17    250,000,000  \n",
       "18    140,000,000  \n",
       "19      8,000,000  \n",
       "20    460,000,000  \n",
       "21    300,000,000  \n",
       "22     11,000,000  \n",
       "23     27,500,000  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fund_df = pd.DataFrame(fund_dict)\n",
    "fund_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f49994d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method WebDriver.close of <selenium.webdriver.chrome.webdriver.WebDriver (session=\"80c390e19757ae85251df6e81f0f25a2\")>>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver.close"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e65f46c",
   "metadata": {},
   "source": [
    "# Q7. Write a program to scrap all the available details of best gaming laptops from digit.in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "77e14e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "adf20bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.digit.in/\"\n",
    "driver.get(url)\n",
    "time.sleep(2)\n",
    "best_gam_laptops = driver.find_element(By.XPATH,\"//div[@class='listing_container']//ul//li[9]\").click()\n",
    "time.sleep(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "050fdec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Laptop_Name = []\n",
    "Operating_sys = []\n",
    "Display = []\n",
    "Processor = []\n",
    "Memory = []\n",
    "Weight = []\n",
    "Dimensions = []\n",
    "Graph_proc = []\n",
    "Price = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e978670e",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (Temp/ipykernel_7632/2241457651.py, line 46)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\BALLBU~1\\AppData\\Local\\Temp/ipykernel_7632/2241457651.py\"\u001b[1;36m, line \u001b[1;32m46\u001b[0m\n\u001b[1;33m    except NoSuchElementException:\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Scraping the data of laptop names\n",
    "laptop_name= driver.find_elements(By.XPATH,\"//div[@class='right-container']/div/a/h3\")\n",
    "for name in laptop_name:\n",
    "    Laptop_Name.append(name.text)\n",
    "    \n",
    "    \n",
    "#Scraping the data of operating system\n",
    "try:\n",
    "    op_sys = driver.find_elements(By.XPATH,\"//div[@class='product-detail']/div/ul/li[1]/div/div\")\n",
    "    for os in op_sys:\n",
    "        Operating_sys.append(os.text)\n",
    "except NoSuchElementException:\n",
    "    pass\n",
    "\n",
    "\n",
    "#Scraping data of display of the laptop\n",
    "try:\n",
    "    display= driver.find_elements(By.XPATH,\"//div[@class='product-detail']/div/ul/li[2]/div/div\")\n",
    "    for disp in display:\n",
    "        Display.append(disp.text)\n",
    "except NoSuchElementException:\n",
    "    pass\n",
    "\n",
    "\n",
    "#Scraping data of Processor\n",
    "try:\n",
    "    processor = driver.find_elements(By.XPATH,\"//div[@class='Spcs-details'][1]/table/tbody/tr[5]/td[3]\")\n",
    "    for pro in processor:\n",
    "        Processor.append(pro.text)\n",
    "except NoSuchElementException:\n",
    "    pass\n",
    "\n",
    "#Scraping data of memory\n",
    "try:\n",
    "    memory = driver.find_elements(By.XPATH,\"//div[@class='Spcs-details'][1]/table/tbody/tr[6]/td[3]\")\n",
    "    for memo in memory:\n",
    "        Memory.append(memo.text)\n",
    "except NoSuchElementException:\n",
    "    pass\n",
    "\n",
    "#Scraping data of weight\n",
    "try:\n",
    "    weight = driver.find_elements(By.XPATH,\"//div[@class='Spcs-details'][1]/table/tbody/tr[7]/td[3]\")\n",
    "    for wgt in weight:\n",
    "        Weight.append(wgt.text)\n",
    "        except NoSuchElementException:\n",
    "    pass\n",
    "\n",
    "#Scraping data of dimensions\n",
    "try:\n",
    "    dimension = driver.find_elements(By.XPATH,\"//div[@class='Spcs-details'][1]/table/tbody/tr[8]/td[3]\")\n",
    "    for dim in dimension:\n",
    "        Dimensions.append(dim.text)\n",
    "except NoSuchElementException:\n",
    "    pass\n",
    "\n",
    "\n",
    "#Scraping data of Graph processor\n",
    "try:\n",
    "    graph = driver.find_elements(By.XPATH,'//div[@class=\"Spcs-details\"]/table/tbody/tr[7]/td[3]')\n",
    "    for gra in graph:\n",
    "        Graph_proc.append(gra.text)\n",
    "except NoSuchElementException:\n",
    "    pass\n",
    "\n",
    "\n",
    "#Scraping data of price\n",
    "try:\n",
    "    price = driver.find_elements(By.XPATH,\"//td[@class='smprice']\")\n",
    "    for pri in price:\n",
    "        Price.append(pri.text.replace('₹','Rs '))\n",
    "except NoSuchElementException:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dcf80279",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0 0 0 0 0 0 0\n"
     ]
    }
   ],
   "source": [
    "print(len(Laptop_Name),len(Operating_sys),len(Display),len(Processor),len(Memory),len(Weight),len(Dimensions),len(Graph_proc),len(Price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "672ab117",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Laptop_Name</th>\n",
       "      <th>Operating_System</th>\n",
       "      <th>Display</th>\n",
       "      <th>Processor</th>\n",
       "      <th>Memory</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Dimension</th>\n",
       "      <th>Graph_Proc</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Laptop_Name, Operating_System, Display, Processor, Memory, Weight, Dimension, Graph_Proc, Price]\n",
       "Index: []"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=list(zip(Laptop_Name, Operating_sys, Display, Processor, Memory, Weight, Dimensions, Graph_proc, Price))\n",
    "df=pd.DataFrame(data,columns=['Laptop_Name','Operating_System','Display','Processor','Memory','Weight','Dimension','Graph_Proc','Price'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ebc0296",
   "metadata": {},
   "source": [
    "# Q8. Write a python program to scrape the details for all billionaires from www.forbes.com.\n",
    "Details to be scrapped: “Rank”, “Name”, “Net worth”, “Age”, “Citizenship”, “Source”, “Industry”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "32dbe45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"chromedriver.exe\")\n",
    "\n",
    "#Getting the specified url\n",
    "url = \"https://www.forbes.com/?sh=69e6b8c92254\"\n",
    "driver.get(url)\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c6191513",
   "metadata": {},
   "outputs": [],
   "source": [
    "button = driver.find_element(By.XPATH,'//div[@class=\"_69hVhdY4\"]')\n",
    "button.click()\n",
    "time.sleep(1)\n",
    "bill = driver.find_element(By.XPATH,'//li[@class=\"TjJgrPSg cD45ib6e primary\"]')\n",
    "bill.click()\n",
    "time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "021a6b81",
   "metadata": {},
   "outputs": [
    {
     "ename": "ElementNotInteractableException",
     "evalue": "Message: element not interactable\n  (Session info: chrome=107.0.5304.88)\nStacktrace:\nBacktrace:\n\tOrdinal0 [0x00E21ED3+2236115]\n\tOrdinal0 [0x00DB92F1+1807089]\n\tOrdinal0 [0x00CC65C0+812480]\n\tOrdinal0 [0x00CF6586+1009030]\n\tOrdinal0 [0x00CEC416+967702]\n\tOrdinal0 [0x00D11A8C+1120908]\n\tOrdinal0 [0x00CEBD84+966020]\n\tOrdinal0 [0x00D11CA4+1121444]\n\tOrdinal0 [0x00D259E2+1202658]\n\tOrdinal0 [0x00D118A6+1120422]\n\tOrdinal0 [0x00CEA73D+960317]\n\tOrdinal0 [0x00CEB71F+964383]\n\tGetHandleVerifier [0x010CE7E2+2743074]\n\tGetHandleVerifier [0x010C08D4+2685972]\n\tGetHandleVerifier [0x00EB2BAA+532202]\n\tGetHandleVerifier [0x00EB1990+527568]\n\tOrdinal0 [0x00DC080C+1837068]\n\tOrdinal0 [0x00DC4CD8+1854680]\n\tOrdinal0 [0x00DC4DC5+1854917]\n\tOrdinal0 [0x00DCED64+1895780]\n\tBaseThreadInitThunk [0x761D6739+25]\n\tRtlGetFullPathName_UEx [0x77B78FD2+1218]\n\tRtlGetFullPathName_UEx [0x77B78F9D+1165]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mElementNotInteractableException\u001b[0m           Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\BALLBU~1\\AppData\\Local\\Temp/ipykernel_7632/2451788544.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mworld_bill\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_element\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mXPATH\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'//li[@class=\"TjJgrPSg _2bNo56RE secondary\"]'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mworld_bill\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclick\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#Creatng empty lists\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mRank\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webelement.py\u001b[0m in \u001b[0;36mclick\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     86\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclick\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m         \u001b[1;34m\"\"\"Clicks the element.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_execute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCommand\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCLICK_ELEMENT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0msubmit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webelement.py\u001b[0m in \u001b[0;36m_execute\u001b[1;34m(self, command, params)\u001b[0m\n\u001b[0;32m    394\u001b[0m             \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    395\u001b[0m         \u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'id'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_id\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 396\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    397\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    398\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfind_element\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mby\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mID\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mWebElement\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    427\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    428\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 429\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    430\u001b[0m             response['value'] = self._unwrap_value(\n\u001b[0;32m    431\u001b[0m                 response.get('value', None))\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    241\u001b[0m                 \u001b[0malert_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'alert'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    242\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 243\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mElementNotInteractableException\u001b[0m: Message: element not interactable\n  (Session info: chrome=107.0.5304.88)\nStacktrace:\nBacktrace:\n\tOrdinal0 [0x00E21ED3+2236115]\n\tOrdinal0 [0x00DB92F1+1807089]\n\tOrdinal0 [0x00CC65C0+812480]\n\tOrdinal0 [0x00CF6586+1009030]\n\tOrdinal0 [0x00CEC416+967702]\n\tOrdinal0 [0x00D11A8C+1120908]\n\tOrdinal0 [0x00CEBD84+966020]\n\tOrdinal0 [0x00D11CA4+1121444]\n\tOrdinal0 [0x00D259E2+1202658]\n\tOrdinal0 [0x00D118A6+1120422]\n\tOrdinal0 [0x00CEA73D+960317]\n\tOrdinal0 [0x00CEB71F+964383]\n\tGetHandleVerifier [0x010CE7E2+2743074]\n\tGetHandleVerifier [0x010C08D4+2685972]\n\tGetHandleVerifier [0x00EB2BAA+532202]\n\tGetHandleVerifier [0x00EB1990+527568]\n\tOrdinal0 [0x00DC080C+1837068]\n\tOrdinal0 [0x00DC4CD8+1854680]\n\tOrdinal0 [0x00DC4DC5+1854917]\n\tOrdinal0 [0x00DCED64+1895780]\n\tBaseThreadInitThunk [0x761D6739+25]\n\tRtlGetFullPathName_UEx [0x77B78FD2+1218]\n\tRtlGetFullPathName_UEx [0x77B78F9D+1165]\n"
     ]
    }
   ],
   "source": [
    "world_bill= driver.find_element(By.XPATH,'//li[@class=\"TjJgrPSg _2bNo56RE secondary\"]')\n",
    "world_bill.click()\n",
    "time.sleep(1)\n",
    "#Creatng empty lists\n",
    "Rank = []\n",
    "Person_Name = []\n",
    "total_net_worth = []\n",
    "Age = []\n",
    "citizenship = []\n",
    "Source = []\n",
    "industry = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "15176500",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'total_net_worth' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\BALLBU~1\\AppData\\Local\\Temp/ipykernel_7632/612049832.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[1;31m#Scraping data of net worth\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[0mNet_Worth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtotal_net_worth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m     \u001b[0mNet_Worth\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtotal_net_worth\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'total_net_worth' is not defined"
     ]
    }
   ],
   "source": [
    "while(True):\n",
    "    #Scraping the data of rank of the billionaires\n",
    "    rank_tags= driver.find_elements(By.XPATH,'//div[@class=\"rank\"]')\n",
    "    for rank in rank_tags:\n",
    "        Rank.append(rank.text)\n",
    "    time.sleep(1)\n",
    "    \n",
    "    \n",
    "    #Scraping the data of names of the billionaires\n",
    "    name_tags= driver.find_elements(By.XPATH,'//div[@class=\"personName\"]/div')\n",
    "    for name in name_tags:\n",
    "        Person_Name.append(name.text)\n",
    "    time.sleep(1)\n",
    "    \n",
    "    \n",
    "    #Scraping data of age of the billionaires\n",
    "    age_tags= driver.find_elements(By.XPATH,'//div[@class=\"age\"]/div')\n",
    "    for age in age_tags:\n",
    "        Age.append(age.text)   \n",
    "    time.sleep(1)\n",
    "    \n",
    "    \n",
    "    #Scraping data of citizenship of the billionaires\n",
    "    cit_tags= driver.find_elements(By.XPATH,'//div[@class=\"countryOfCitizenship\"]')\n",
    "    for cit in cit_tags:\n",
    "        citizenship.append(cit.text)\n",
    "    time.sleep(1)\n",
    "    \n",
    "    \n",
    "    #Scraping data of source of income of the billionaires\n",
    "    sour_tags= driver.find_elements(By.XPATH,'//div[@class=\"source\"]')\n",
    "    for sour in sour_tags:\n",
    "        Source.append(sour.text)    \n",
    "    time.sleep(1)\n",
    "    \n",
    "    \n",
    "    #Scraping data of Industry of the billionaires\n",
    "    ind_tags= driver.find_elements(By.XPATH,'//div[@class=\"category\"]//div')\n",
    "    for ind in ind_tags:\n",
    "        industry.append(ind.text)\n",
    "        #scraping data of net_worth of billionaires\n",
    "    net_tags= driver.find_elements(By.XPATH,'//div[@class=\"netWorth\"]//div[1]')\n",
    "    for net in net_tags:\n",
    "        total_net_worth.append(net.text)\n",
    "    time.sleep(1)\n",
    "    \n",
    "    #Clicking on next button\n",
    "    try:\n",
    "        next_button = driver.find_element(By.XPATH,\"//button[@class='pagination-btn pagination-btn--next ']\")\n",
    "        next_button.click()\n",
    "    except:\n",
    "        break\n",
    "        \n",
    "#Scraping data of net worth\n",
    "Net_Worth = []\n",
    "for i in range(0,len(total_net_worth),2):\n",
    "    Net_Worth.append(total_net_worth[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "74133573",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Rank' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\BALLBU~1\\AppData\\Local\\Temp/ipykernel_7632/412045177.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mBillionaires\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mBillionaires\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Rank'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRank\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mBillionaires\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Names'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPerson_Name\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mBillionaires\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Net Worth'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNet_Worth\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mBillionaires\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Age'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAge\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Rank' is not defined"
     ]
    }
   ],
   "source": [
    "Billionaires=pd.DataFrame({})\n",
    "Billionaires['Rank'] = Rank\n",
    "Billionaires['Names'] = Person_Name\n",
    "Billionaires['Net Worth'] = Net_Worth\n",
    "Billionaires['Age'] = Age\n",
    "Billionaires['Citizenship'] = citizenship\n",
    "Billionaires['Source'] = Source\n",
    "Billionaires['Industry'] = industry\n",
    "Billionaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b1664d13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method WebDriver.close of <selenium.webdriver.chrome.webdriver.WebDriver (session=\"13a1accd5ca32014589b172b336596e1\")>>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Billionaires.to_csv(\"Forbes_Billionaries.csv\")\n",
    "driver.close"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d6f4040",
   "metadata": {},
   "source": [
    "# Q9. Write a program to extract at least 500 Comments, Comment upvote and time when comment was posted from any YouTube Video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d8da7f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"chromedriver.exe\") \n",
    "time.sleep(2)\n",
    "\n",
    "url = \"https://www.youtube.com/\"\n",
    "driver.get(url)\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "82dffcef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the video you want to search : Sidemen : WHO IS THE BEST SIDEMEN FOOTBALL PLAYER?\n"
     ]
    }
   ],
   "source": [
    "user_input = input('Enter the video you want to search : ')\n",
    "\n",
    "#finding element for search bar\n",
    "search_bar = driver.find_element(By.XPATH,'//input[@id=\"search\"]')\n",
    "search_bar.send_keys(user_input)\n",
    "time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "36aac3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_btn = driver.find_element(By.ID,\"search-icon-legacy\")  \n",
    "search_btn.click()\n",
    "time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d681610b",
   "metadata": {},
   "outputs": [],
   "source": [
    "link_click = driver.find_element(By.XPATH,\"//yt-formatted-string[@class ='style-scope ytd-video-renderer']\")\n",
    "link_click.click()\n",
    "\n",
    "for _ in range(10000):\n",
    "    driver.execute_script(\"window.scrollBy(0,10000)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0b2fff24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Pie looks incredible and I love that man',\n",
       " 'I can’t wait until JJ does 5 Sidemen Sundays on his own to catch up ',\n",
       " \"My man Vik showed both technique and precision by aiming at the same defender over and over again, even I couldn't do that.\",\n",
       " 'Simon looks so genuinely happy in this video - he is in his element. The Brown family have some seriously athletic genes.',\n",
       " 'Tobi saying “that’s my brother” actually is so cute ',\n",
       " 'i love how supportive everyone is to pie the whole video',\n",
       " 'I like how Vik went easy on these noobs. What a great guy.',\n",
       " 'Simon is so happy, when he makes Football content. He should do it more often.',\n",
       " 'Vik staying humble to up the confidence of his teammates. He will show his true self in the real match.',\n",
       " 'Big up the Brown’s parents, Tobi and Manny are so nice',\n",
       " '28:10 Harry and Chris are my last two brain cells at 2 A.M',\n",
       " 'Nothing hits more than a cold Sunday watching sidemen wrapped up warm with a hot drink good vibes. Can’t wait for the match',\n",
       " 'Vik is so down to Earth. He thought he’d go ez mode on these scrubs to give them a chance. What a hero',\n",
       " 'The amount of happiness and goosebumps I fell when Vik scored the first goal for sidemen was way more than when I felt after We Won! \\nIt was some quality production and play also \\nAlso respect for Simon... He is a well deserved MvP ',\n",
       " 'Honestly respect for VIK for having  the same boots for 3years + love that guy ',\n",
       " 'Simon’s happiness when playing football is so wholesome',\n",
       " '22:45 that kick from Harry tho',\n",
       " \"Vik is such a humble guy. He didn't show his true punjabi powers as it would intimidate the boys.\",\n",
       " '48:10 JJ would be proud of that laugh \\U0001f979',\n",
       " 'this really brought back old sidemen football challenges vibes, absolutely loved it',\n",
       " 'Vik improved basically every shot and is pure comedy loved seeing everyone in this vid ',\n",
       " \"31:55 I haven't laughed that hard in ages \",\n",
       " 'Mad respect to Pie Face for that amazing transformation. Incredible.',\n",
       " \"The excited 'that's my brother' from Tobi was so lovely\",\n",
       " '28:10 the sight of Harry dancing never fails to amuse me ',\n",
       " \"Never seen any of Pies content but from this video he seems like an awesome guy can't wait to watch the charity match\",\n",
       " 'Respect to ishowspeed for entertaining everybody , he clearly made the match 10x better and interesting.',\n",
       " 'Simon is just too good at everything he does  god tier',\n",
       " 'The freaking editing on this video is ... That little switch from cr7 to Simon is so satisfying to watch. Great job honestly',\n",
       " 'That bit with Keane continuously roasting Pieface is the funniest thing',\n",
       " 'The fact that VIK blessed this video with his football god presence, such a giving man',\n",
       " '25:34 - I have not laughed like that for a minute  Respect to Vik',\n",
       " '39:59 ; The editor needs a raise, clean asf.',\n",
       " 'oldschool sidemen. the whole video was such a nice throwback',\n",
       " '33:10 I dont think Vikk realises how sick that goal is',\n",
       " 'Vik is getting so funny and entertaining ',\n",
       " 'Vik is so humble he didn’t show his true powers so the others wouldn’t be humiliated',\n",
       " 'Can we just talk about the LEGEND that is Pie?!? Dude looks incredible! So happy for him and proud of that man',\n",
       " \"sidemen should do more football videos, they're always so entertaining\",\n",
       " 'A lot of people won’t appreciate this is classic Sidemen content',\n",
       " 'As much as this could be a second channel video \\nThere consistency is unmatched and to put a video out every Sunday all year round for years  is always gonna be hard to please everyone and to keep up with the trends and release bangers all the time it isn’t  easy so gotta give credit at least they release something every other Sunday without fail',\n",
       " \"All jokes aside, I love how supportive they are of Vik even though football's clearly not his thing.\",\n",
       " 'Tobi so happy his brother did that incredible touch',\n",
       " 'I couldnt hold back laughing at the slo-mo of viks volley',\n",
       " 'Not seeing many comments about how incredible pie face looks? Looks like a different human being all together, congrats to him.',\n",
       " 'why is no one talking about how ethan said “i ate the floor on that one” and callux  goes “i’m not suprised”',\n",
       " 'That first ball control from Manny was so ',\n",
       " 'The way vik runs is the highlight of the day',\n",
       " 'Manny seems to be so much more confident and lively in front of camera and well done pieface for the crazy weightloss. Both Sidemen and associates are inspiring through the roof. Much love to all',\n",
       " \"Been a while since we've had a simple football video for a sidemen Sunday, pleasant surprise!\\n\\nExcited for the match!\",\n",
       " '48:00 Its a miracle. Tobi can walk normally after those shots.',\n",
       " 'play also Also respect for Simon... He is a well deserved MvP',\n",
       " 'Well done Pieface. Incredible transformation ️️️',\n",
       " \"28:07 is the best most unexpected laugh i've had in a long time\",\n",
       " 'Love how Tobi and Josh were just there standing around like Ant and Dec.',\n",
       " 'I’d honestly love to see more driving videos. These are awesome too but the driving videos are amazing. Love your guys’ content though! <3',\n",
       " \"I like how the editors took Bakers reaction to Simons free kick and put it in the build up to Chris's free kick... Nice touch lads\",\n",
       " 'Bruh the memories this video brought back is out of this world. Feels like the old days <3',\n",
       " 'Josh: Vikk ?\\nSimon: Solid ! ',\n",
       " '32:19 Ethan: “I ate the floor on that”\\nCallux: “I’m not surprised”\\n\\nCallux was hilarious in this video ',\n",
       " 'When they insult Simon  Harry and Bez just going at it had me lmaooo',\n",
       " 'People love how Tobi and Josh were just there standing around like Ant and Dec.',\n",
       " 'Karl was pretty good too, knew his positioning and wasn’t overly aggressive. He wasn’t the best, but he was up there.',\n",
       " 'Manny: does a godly touch\\nTobi: “that’s my brother”\\n\\nSo Wholesome',\n",
       " 'Great vid. we need more, had me laughing',\n",
       " \"So proud of Pie, man's looking great!\\n\\nExcited to see the match at the end of this month :)\",\n",
       " 'Officially, simon is the best youtube footballer ',\n",
       " 'The editing team constantly memeing the goalkeeper killed me ',\n",
       " \"31:55 I haven't laughed that hard in ages\",\n",
       " '34:29 that LeBron \"silencer\" celebration',\n",
       " 'Sidemen soccer videos bring back so much great nostalgia ',\n",
       " 'Vik is a legend bro went easy on these guys respect',\n",
       " 'I really enjoy the fitness videos they always make me laugh and are always enjoyable to watch never fail to make me click and rewatch  much love ',\n",
       " 'Harry asked for it to be on the other side and when they changed it he immediately scored a banger.',\n",
       " 'Loved finally seeing a football video again ',\n",
       " 'Shout out to pie Hes done so well in his weight loss journey he looks so good congratulations Pie ',\n",
       " 'Jesus. That control by Manny when Tobi dropped the ball is unreal!',\n",
       " 'Simon is actually the best footbal youtuber ever',\n",
       " 'Manny is destined for greatness',\n",
       " 'Nothing to make your sunday better than sidemen posting',\n",
       " 'I love that manny is finally in a video he is so underrated hope he is some more videos soon he is so good',\n",
       " 'I JUST LOVE THE SIDEMEN AND THEIR FOOTBALL VIDEOS. TILL THE END OF TIME BRO ALWAYS GONNA LOVE THESE PPL FRFR',\n",
       " 'When I watch these videos, I respect every time Vik shows up.',\n",
       " 'Genuinely Simon is capable of being a pro footballer.',\n",
       " \"I can't lie, this might be the best Sidemen Charity Match ever\",\n",
       " '\"Declan ate too much rice\" probably the most hilarious thing i heard today. ',\n",
       " 'pie face was genuinely one of the best parts of the vid. good man',\n",
       " \"31:56 Theo hit both targets, but it didn't go in. That is special talent.\\nSimon being a weirdo, like in every football video, because no normal person does that\",\n",
       " '22:50 pure perfection',\n",
       " 'Behz lifting his shirt and running to the stands had me dying ',\n",
       " 'Chris is so competitive I love it haha',\n",
       " \"It is impressive seeing vick's free quick quality he hitted the same manequim cause the goal was so big so he made his target the 4th manequim\",\n",
       " 'Vik and that free-kick was funnysuch a lovely guy',\n",
       " 'I love the football vids and holiday vids keep ip the good work',\n",
       " 'The edits make it wayyyyyyy more fun',\n",
       " 'crying cause its just like the old days. these will always be my favorite type of videos',\n",
       " \"31:47 had me in stitches! Can't believe that happened!\",\n",
       " 'Man the editing is on point',\n",
       " 'Honestly respect for VIK for having the same boots for 3years + love that guy',\n",
       " 'fkn loved this video brought back the old sidemen football challenges times that I miss so much',\n",
       " 'The Roy Keane commentary towards pie face was class!',\n",
       " '4:32 - Great ball control Behz',\n",
       " 'Idk why but Chris and Harry singing fifa points is so funny',\n",
       " 'Can we please just apreciate the editing on this video',\n",
       " 'when Harry runs straight out to congratulate callux ',\n",
       " 'I love the story and I love your video. Excellent animation. Have a nice time everyone.',\n",
       " 'It has been a long time since we have seen a Football Sidemen Sunday. I really enjoyed that !',\n",
       " 'The football memes were amazing ️',\n",
       " 'This is a banging video!\\nThe best in a while',\n",
       " 'Vik is Soo inspirational man, he could have used his Punjabi sause to body these merchants but he choose to stay humble ',\n",
       " 'I really wanna see more of Manny!',\n",
       " \"Honestly looking forward to see vik play again. I reckon he's improved a lot more\",\n",
       " 'the sidemen knew this was a stinky video idea but they managed to add so many different elements like the fans and old clips to make the video a banger classic football video love it',\n",
       " 'We need a new strength tetst as a sidemen sunday soon',\n",
       " 'I can’t wait for the charity match',\n",
       " \"Sideman.  Y'all should do a 20 women vs 1 with nicko.  I think it will really be breathtaking cause damn nicko really savage as.\",\n",
       " 'Theos reaction to simons goal ',\n",
       " 'Vik’s face after that volley killed me off',\n",
       " 'Watching the video after the charity match and they foreshadowed the Theo free kick and pie saved it. Lol wild.',\n",
       " 'I love the Scott Sterling call back ',\n",
       " 'Those free kicks from Simon were actually cold',\n",
       " 'The touch by Manny was insanely good',\n",
       " 'This video had me laughing the whole way through Harry shouting “it’s on the wrong side” priceless ',\n",
       " 'this had the vibe of an OG sidemen video i love it',\n",
       " 'Theo looks like someone who doesn’t know F of Football but is actually good.',\n",
       " 'That Manny control was filth. Exquisite touch.',\n",
       " \"I don't really like videos on YouTube, but that control touch by Manny was so insane that I just remembered that I had to SMASH that like button.\",\n",
       " \"I can't believe Vikk still plays with these wetbags. Truly holding him back, what a humble guy.\",\n",
       " \"39:57 The transition, the music kicking in, the edit, the shot and the reaction of the boys made this moment one of the best one i've seen in a while, what a masterpiece.\",\n",
       " 'What a nice group of fans cheering to sidemen ',\n",
       " '“Let’s go Paul\"  best thing I have ever heard',\n",
       " 'That touch by Manny was INSANE',\n",
       " \"Theo's laugh at 48:10 sounds just like JJ \",\n",
       " \"Toby is really nice but he's still a brother, the way he told the people to boo Manny \",\n",
       " 'Bro i loved ur vids after yrs of football like all of them together bro its jus amazin missin jj tho he made it more funnier',\n",
       " '20:08 are we just gonna ignore this unique handshake between josh and simon?',\n",
       " 'Behz:\"I ate the floor on that (shot)\"\\nHarry below his breath: \"I\\'m not surprised\"\\n\\ncarry me away on a stretcher please',\n",
       " '48:09 i was searching the video for JJ here. didnt realise theo could laugh the same',\n",
       " 'Pie face looks great, I didn’t even realise it was him at first. Fair play to him',\n",
       " \"When Theo hit the post from one inch away..... I haven't laughed that much since Theo's last appearance in blind date. Put the man in more videos!\",\n",
       " 'I’m super excited for the charity match . LETS GOOOOOO',\n",
       " '13:28 wholesome moment',\n",
       " 'My favourite part was when Tobi said \"It\\'s Tobin\\' time\" and jizzled all of his balls into the net. Truly the sidemen moment of all time.',\n",
       " '28:09 my favourite part ',\n",
       " 'GREAT VIDEO ',\n",
       " '45:49 Toby and Manny look so cute and small in the line up with the boys',\n",
       " 'The boys are well aware of the fact that we loveee it when vik does anything great so they like come onnn man pls we need this for the vid lool',\n",
       " 'Ethan: “I ate the floor on that.”\\nLux: “Not surprised.”',\n",
       " \"The edit for viks' volley killed me\",\n",
       " 'the editors came with the memes and it was great',\n",
       " '13:18 is such a beautiful moment. I replayed it like 5 times',\n",
       " 'Ethan: \"I ate the floor on that\"\\nCallux: \"Not surprised\" LMAO',\n",
       " 'The editing was great on this one',\n",
       " \"I felt like I'm the football player watching this! \",\n",
       " 'This was so funny. \\nLots of laughs',\n",
       " 'Can’t wait for the charity match',\n",
       " 'It makes me laugh how from one minute to the next Harry and Simon are best friends and then enemies',\n",
       " 'No one is appreciating theo, bro is actually a beast',\n",
       " '\"People aren\\'t expecting great things from me, so i\\'m not giving them great things.\" -Callux',\n",
       " 'Manny got OBJECTIFIED af',\n",
       " \"Ayoo, Theo Baker's miss just about killed me \",\n",
       " 'cant wait for this been a massive fan',\n",
       " 'Manny is so talented at football its literally ridiculous, its like watching an artist',\n",
       " '39:58\\nNo cap that ronaldo/miniminter edit looks sick af',\n",
       " 'The way simon celebrated is so fing funny',\n",
       " 'Hopefully this even gets pieface close to a million subs he deserves it so much',\n",
       " 'ChipFat is a legend ',\n",
       " 'I like how everyone has a jersey and Callux looks like he came out of a Sunday Leauge',\n",
       " 'No other way to start my week better than sidemen Sunday and Harry showing middle finger',\n",
       " 'Vik is such a nice guy. He didn’t show his Cajun powers in this soccer match',\n",
       " 'Harry’s volley was class.',\n",
       " 'Pie face almost dies when he tries to save viks shot ',\n",
       " 'Finally a football video !!!',\n",
       " '11:27 Vik also got all 3 on target lol',\n",
       " 'Its so wholesome how Josh helps and trys to support vik at the Freekicks',\n",
       " 'Can’t wait for the charity match!',\n",
       " 'Using the sound clip from the Scott Sterling video was a stroke of genius',\n",
       " '13:20 u can tell vik don’t ball cause if he did he would been reacting like the other boys did to that ',\n",
       " 'I died when someone shouted “cmon ginge” on Ethan’s penalty',\n",
       " \"pie has lost so much weight I'm actually so happy for him\",\n",
       " 'Every week it feels like the sidemen Sundays are coming quicker ',\n",
       " 'The Roy Keane clips makes this so much funnier',\n",
       " 'Simon’s happiness when playing football is so wholesome',\n",
       " 'Vik is so down to Earth. He thought he’d go ez mode on these scrubs to give them a chance. What a hero',\n",
       " 'The fact that VIK blessed this video with his football god presence, such a giving man',\n",
       " '48:10 JJ would be proud of that laugh \\U0001f979',\n",
       " 'oldschool sidemen. the whole video was such a nice throwback',\n",
       " 'play also Also respect for Simon... He is a well deserved MvP',\n",
       " 'Nothing hits more than a cold Sunday watching sidemen wrapped up warm with a hot drink good vibes. Can’t wait for the match',\n",
       " \"Vik is such a humble guy. He didn't show his true punjabi powers as it would intimidate the boys.\",\n",
       " 'I can’t wait for the charity match',\n",
       " \"Honestly looking forward to see vik play again. I reckon he's improved a lot more\",\n",
       " 'I like how Vik went easy on these noobs. What a great guy.',\n",
       " 'Not seeing many comments about how incredible pie face looks? Looks like a different human being all together, congrats to him.',\n",
       " 'Simon’s happiness when playing football is so wholesome',\n",
       " 'Simon’s happiness when playing football is so wholesome',\n",
       " 'Simon’s happiness when playing football is so wholesome',\n",
       " 'Nothing hits more than a cold Sunday watching sidemen wrapped up warm with a hot drink good vibes. Can’t wait for the match',\n",
       " 'Vik is so down to Earth. He thought he’d go ez mode on these scrubs to give them a chance. What a hero',\n",
       " 'Simon’s happiness when playing football is so wholesome',\n",
       " 'Every week it feels like the sidemen Sundays are coming quicker ',\n",
       " 'The Roy Keane clips makes this so much funnier',\n",
       " 'Simon’s happiness when playing football is so wholesome',\n",
       " 'Vik is so down to Earth. He thought he’d go ez mode on these scrubs to give them a chance. What a hero',\n",
       " 'The fact that VIK blessed this video with his football god presence, such a giving man',\n",
       " '48:10 JJ would be proud of that laugh \\U0001f979',\n",
       " 'oldschool sidemen. the whole video was such a nice throwback',\n",
       " 'play also Also respect for Simon... He is a well deserved MvP',\n",
       " 'Nothing hits more than a cold Sunday watching sidemen wrapped up warm with a hot drink good vibes. Can’t wait for the match',\n",
       " \"Vik is such a humble guy. He didn't show his true punjabi powers as it would intimidate the boys.\",\n",
       " 'I can’t wait for the charity match',\n",
       " \"Honestly looking forward to see vik play again. I reckon he's improved a lot more\",\n",
       " 'I like how Vik went easy on these noobs. What a great guy.',\n",
       " 'Not seeing many comments about how incredible pie face looks? Looks like a different human being all together, congrats to him.',\n",
       " 'Simon’s happiness when playing football is so wholesome',\n",
       " 'Simon’s happiness when playing football is so wholesome',\n",
       " 'Simon’s happiness when playing football is so wholesome',\n",
       " 'Nothing hits more than a cold Sunday watching sidemen wrapped up warm with a hot drink good vibes. Can’t wait for the match',\n",
       " 'Vik is so down to Earth. He thought he’d go ez mode on these scrubs to give them a chance. What a hero',\n",
       " 'Simon’s happiness when playing football is so wholesome',\n",
       " 'Viks hiding his real power .. Damnn mann',\n",
       " 'We gonna ignore how chrismd scratches his balls at 27 mins ',\n",
       " 'Tobjizzle\\'s \"that\\'s my brother\" is wholesome',\n",
       " 'Sidemen needs to make more football videos!',\n",
       " '25:44 the way his leg wobble like a goofy cartoon character is just beyond funny, I am crying ',\n",
       " 'Harry and Chris dancing at 28:10 ',\n",
       " 'Yoooo the edit on simon‘s freekick was coooooold',\n",
       " 'My god my eyes are bleeding of al those shots haha, nice videa guys well done',\n",
       " 'Man, I miss football videos from them.',\n",
       " 'will someone please teach vikk the mechanics of kicking, please god',\n",
       " \"Honestly looking forward to see vik play again. I reckon he's improved a lot more\",\n",
       " 'Behz got 3 on the passing challenge, that ball rode the inside of the rim.',\n",
       " 'The editing ',\n",
       " 'this hits different after the charity match',\n",
       " 'Simon free kick was nuts',\n",
       " 'Pie face is just an amazing YouTube keeper',\n",
       " '11:20 vikstar saying ethan was probably best at penalties and at the same time ethan saying vik was worst at it had me dying',\n",
       " 'Pie looks fantastic, fair play!',\n",
       " 'behz and simon chcking out mannys back had my crying',\n",
       " 'Pie looks fantastic, fair play!']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments = []\n",
    "comment_time = []\n",
    "Time = []\n",
    "Likes = []\n",
    "No_of_Likes = []\n",
    "\n",
    "# to scrape comments\n",
    "cm_tags = driver.find_elements(By.ID,\"content-text\")\n",
    "for cm in cm_tags:\n",
    "    if cm.text is None:\n",
    "        comments.append(\"--\")\n",
    "    else:\n",
    "        comments.append(cm.text)\n",
    "time.sleep(5)\n",
    "comments[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "66a945ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "240"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5807655a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " '25K',\n",
       " '',\n",
       " '5.2K',\n",
       " '',\n",
       " '1.6K',\n",
       " '',\n",
       " '443',\n",
       " '',\n",
       " '1.9K',\n",
       " '',\n",
       " '255',\n",
       " '',\n",
       " '7.8K',\n",
       " '',\n",
       " '872',\n",
       " '',\n",
       " '471',\n",
       " '',\n",
       " '175',\n",
       " '',\n",
       " '97',\n",
       " '',\n",
       " '228',\n",
       " '',\n",
       " '7.5K',\n",
       " '',\n",
       " '42',\n",
       " '',\n",
       " '61',\n",
       " '',\n",
       " '7',\n",
       " '',\n",
       " '242',\n",
       " '',\n",
       " '12K',\n",
       " '',\n",
       " '177',\n",
       " '',\n",
       " '44',\n",
       " '',\n",
       " '10',\n",
       " '',\n",
       " '100',\n",
       " '',\n",
       " '5K',\n",
       " '',\n",
       " '75',\n",
       " '',\n",
       " '43',\n",
       " '',\n",
       " '21',\n",
       " '',\n",
       " '12',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '14',\n",
       " '',\n",
       " '6',\n",
       " '',\n",
       " '3.5K',\n",
       " '',\n",
       " '7',\n",
       " '',\n",
       " '18',\n",
       " '',\n",
       " '13',\n",
       " '',\n",
       " '62',\n",
       " '',\n",
       " '6',\n",
       " '',\n",
       " '3.6K',\n",
       " '',\n",
       " '34',\n",
       " '',\n",
       " '3',\n",
       " '',\n",
       " '15',\n",
       " '',\n",
       " '1',\n",
       " '',\n",
       " '3.4K',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '6',\n",
       " '',\n",
       " '182',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '10',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '1.7K',\n",
       " '',\n",
       " '8',\n",
       " '',\n",
       " '12',\n",
       " '',\n",
       " '4',\n",
       " '',\n",
       " '7',\n",
       " '',\n",
       " '6',\n",
       " '',\n",
       " '1K',\n",
       " '',\n",
       " '11',\n",
       " '',\n",
       " '25',\n",
       " '',\n",
       " '4',\n",
       " '',\n",
       " '50',\n",
       " '',\n",
       " '2.3K',\n",
       " '',\n",
       " '10',\n",
       " '',\n",
       " '35',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '1.1K',\n",
       " '',\n",
       " '1',\n",
       " '',\n",
       " '6',\n",
       " '',\n",
       " '8',\n",
       " '',\n",
       " '5',\n",
       " '',\n",
       " '6',\n",
       " '',\n",
       " '669',\n",
       " '',\n",
       " '2',\n",
       " '',\n",
       " '3',\n",
       " '',\n",
       " '1',\n",
       " '',\n",
       " '1',\n",
       " '',\n",
       " '4',\n",
       " '',\n",
       " '10',\n",
       " '',\n",
       " '2',\n",
       " '',\n",
       " '9',\n",
       " '',\n",
       " '6',\n",
       " '',\n",
       " '2.4K',\n",
       " '',\n",
       " '1',\n",
       " '',\n",
       " '1',\n",
       " '',\n",
       " '2',\n",
       " '',\n",
       " '1',\n",
       " '',\n",
       " '1K',\n",
       " '',\n",
       " '5',\n",
       " '',\n",
       " '1',\n",
       " '',\n",
       " '17',\n",
       " '',\n",
       " '6',\n",
       " '',\n",
       " '958',\n",
       " '',\n",
       " '1',\n",
       " '',\n",
       " '1',\n",
       " '',\n",
       " '3',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '1',\n",
       " '',\n",
       " '488',\n",
       " '',\n",
       " '1',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '2',\n",
       " '',\n",
       " '2',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '7',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '5',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '510',\n",
       " '',\n",
       " '3',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '1',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '755',\n",
       " '',\n",
       " '1',\n",
       " '',\n",
       " '3',\n",
       " '',\n",
       " '1',\n",
       " '',\n",
       " '6',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '3',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '1',\n",
       " '',\n",
       " '5',\n",
       " '',\n",
       " '2',\n",
       " '',\n",
       " '508',\n",
       " '',\n",
       " '1',\n",
       " '',\n",
       " '4',\n",
       " '',\n",
       " '1',\n",
       " '',\n",
       " '3',\n",
       " '',\n",
       " '7',\n",
       " '',\n",
       " '371',\n",
       " '',\n",
       " '5',\n",
       " '',\n",
       " '1',\n",
       " '',\n",
       " '2',\n",
       " '',\n",
       " '1',\n",
       " '',\n",
       " '770',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '24',\n",
       " '',\n",
       " '2',\n",
       " '',\n",
       " '1',\n",
       " '',\n",
       " '395',\n",
       " '',\n",
       " '1',\n",
       " '',\n",
       " '5',\n",
       " '',\n",
       " '1',\n",
       " '',\n",
       " '1',\n",
       " '',\n",
       " '1',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '1',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '1',\n",
       " '',\n",
       " '2',\n",
       " '',\n",
       " '202',\n",
       " '',\n",
       " '7',\n",
       " '',\n",
       " '2',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '1',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '263',\n",
       " '',\n",
       " '1',\n",
       " '',\n",
       " '8',\n",
       " '',\n",
       " '2',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '280',\n",
       " '',\n",
       " '8',\n",
       " '',\n",
       " '1',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '1',\n",
       " '',\n",
       " '2',\n",
       " '',\n",
       " '365',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '1',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '1',\n",
       " '',\n",
       " '2',\n",
       " '',\n",
       " '228',\n",
       " '',\n",
       " '1',\n",
       " '',\n",
       " '1',\n",
       " '',\n",
       " '6',\n",
       " '',\n",
       " '1',\n",
       " '',\n",
       " '1',\n",
       " '',\n",
       " '206',\n",
       " '',\n",
       " '1',\n",
       " '',\n",
       " '4K',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '1.3K',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '97',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '139',\n",
       " '',\n",
       " '1',\n",
       " '',\n",
       " '1',\n",
       " '',\n",
       " '1',\n",
       " '',\n",
       " '1.9K',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '1',\n",
       " '',\n",
       " '206',\n",
       " '',\n",
       " '1',\n",
       " '',\n",
       " '4K',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '1.3K',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '97',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '139',\n",
       " '',\n",
       " '1',\n",
       " '',\n",
       " '1',\n",
       " '',\n",
       " '1',\n",
       " '',\n",
       " '1.9K',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '1',\n",
       " '',\n",
       " '1',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '3',\n",
       " '',\n",
       " '1',\n",
       " '',\n",
       " '275',\n",
       " '',\n",
       " '1',\n",
       " '',\n",
       " '1',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '1',\n",
       " '',\n",
       " '1',\n",
       " '',\n",
       " '519',\n",
       " '',\n",
       " '2',\n",
       " '',\n",
       " '1',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '1',\n",
       " '',\n",
       " '1',\n",
       " '',\n",
       " '156',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '2',\n",
       " '',\n",
       " '']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to scrape time when comment was posted\n",
    "tm_tags = driver.find_elements(By.XPATH,\"//a[contains(text(),'ago')]\")\n",
    "for tm in tm_tags:\n",
    "    if tm.text is None:\n",
    "        Time.append(\"--\")\n",
    "    else:\n",
    "        Time.append(tm.text)\n",
    "\n",
    "for i in range(0,len(Time),2):\n",
    "    comment_time.append(Time[i])\n",
    "time.sleep(5)\n",
    "comment_time[:500]\n",
    "\n",
    "# to scrape comment likes\n",
    "like_tags = driver.find_elements(By.XPATH,\"//span[@class='style-scope ytd-comment-action-buttons-renderer']\")\n",
    "for like in like_tags:\n",
    "    if like.text is None:\n",
    "        Likes.append(\"--\")\n",
    "    else:\n",
    "        Likes.append(like.text)\n",
    "    \n",
    "for i in range(1,len(Likes),2):\n",
    "    No_of_Likes.append(Likes[i])\n",
    "Likes[:500]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d0d190a7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length of values (120) does not match length of index (240)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\BALLBU~1\\AppData\\Local\\Temp/ipykernel_7632/4012100562.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mYoutube\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mYoutube\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Comments'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcomments\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m500\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mYoutube\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Comment_time'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcomment_time\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m500\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mYoutube\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Comment upvotes'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNo_of_Likes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m500\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3610\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3611\u001b[0m             \u001b[1;31m# set column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3612\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3613\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3614\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mslice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_set_item\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3782\u001b[0m         \u001b[0mensure\u001b[0m \u001b[0mhomogeneity\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3783\u001b[0m         \"\"\"\n\u001b[1;32m-> 3784\u001b[1;33m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3785\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3786\u001b[0m         if (\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_sanitize_column\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m   4507\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4508\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_list_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4509\u001b[1;33m             \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequire_length_match\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4510\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0msanitize_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4511\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\common.py\u001b[0m in \u001b[0;36mrequire_length_match\u001b[1;34m(data, index)\u001b[0m\n\u001b[0;32m    529\u001b[0m     \"\"\"\n\u001b[0;32m    530\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 531\u001b[1;33m         raise ValueError(\n\u001b[0m\u001b[0;32m    532\u001b[0m             \u001b[1;34m\"Length of values \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    533\u001b[0m             \u001b[1;34mf\"({len(data)}) \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Length of values (120) does not match length of index (240)"
     ]
    }
   ],
   "source": [
    "Youtube=pd.DataFrame({})\n",
    "Youtube['Comments'] = comments[:500]\n",
    "Youtube['Comment_time'] = comment_time[:500]\n",
    "Youtube['Comment upvotes'] = No_of_Likes[:500]\n",
    "\n",
    "#Printing dataframe\n",
    "Youtube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "087379bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method WebDriver.close of <selenium.webdriver.chrome.webdriver.WebDriver (session=\"776b63dc14b055cea2cd6445eb982dfe\")>>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver.close"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c0928c",
   "metadata": {},
   "source": [
    "# Q10. Write a python program to scrape a data for all available Hostels from https://www.hostelworld.com/ in “London” location.\n",
    "You have to scrape hostel name, distance from city centre, ratings, total reviews, overall reviews, privates from price, dorms from price, facilities and property description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "376b51ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(r'chromedriver.exe')\n",
    "driver.get(\"https://www.hostelworld.com/\")\n",
    "driver.maximize_window()\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c781770d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#select london\n",
    "driver.find_element(By.ID,'location-text-input-field').click()\n",
    "time.sleep(2)\n",
    "driver.find_element(By.XPATH,'//*[@id=\"search-input-field\"]').send_keys('London')\n",
    "time.sleep(4)\n",
    "\n",
    "\n",
    "# do click on search button\n",
    "driver.find_element(By.XPATH,'//*[@id=\"predicted-search-results\"]/li[2]').click()\n",
    "driver.find_element(By.ID,'search-button').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5bc7cbb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make empty lists\n",
    "Hostel_Name = []\n",
    "Distance = []\n",
    "overall_review = []\n",
    "total_reviews = []\n",
    "facilities = []\n",
    "price = []\n",
    "Rating = []\n",
    "property_description = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7e1aa10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "while(True):\n",
    "    \n",
    "    # Hostel name\n",
    "    names = driver.find_elements(By.XPATH,'//h2[@class=\"title title-6\"]')\n",
    "    for name in names:\n",
    "        Hostel_Name.append(name.text)\n",
    "    time.sleep(2)\n",
    "        \n",
    "    # Distance from city\n",
    "    distance = driver.find_elements(By.XPATH,'//span[@class=\"description\"]')\n",
    "    for d in distance:\n",
    "        Distance.append(d.text)\n",
    "    time.sleep(2)\n",
    "        \n",
    "    #Review    \n",
    "    review = driver.find_elements(By.XPATH,'//div[@class=\"keyword\"]//span')\n",
    "    for r in review:\n",
    "        overall_review.append(r.text)\n",
    "    time.sleep(2)\n",
    "    \n",
    "    # Total number of reviews     \n",
    "    t_review = driver.find_elements(By.XPATH,'//div[@class=\"reviews\"]')\n",
    "    for t in t_review:\n",
    "        total_reviews.append(t.text)\n",
    "    time.sleep(2)\n",
    "    \n",
    "    # facilities\n",
    "    service = driver.find_elements(By.XPATH,'//div[@class=\"facilities-label facilities\"]')\n",
    "    for s in service:\n",
    "        facilities.append(s.text)\n",
    "    time.sleep(2)\n",
    "    \n",
    "    # Prices    \n",
    "    prices = driver.find_elements(By.XPATH,'//div[@class=\"price-col\"]')\n",
    "    for p in prices:\n",
    "        price.append(p.text)\n",
    "        time.sleep(2)    \n",
    "    try:\n",
    "        next_button = driver.find_element(By.XPATH,'//div[@class=\"pagination-item pagination-next\"]')\n",
    "        next_button.click()\n",
    "    except:\n",
    "        break\n",
    "        \n",
    "        time.sleep(2) \n",
    "\n",
    "# Separate  Privates_From price  and  Dorms_From price\n",
    "private = []\n",
    "for i in range(0,len(price),2):\n",
    "    private.append(price[i])\n",
    "time.sleep(2)\n",
    "\n",
    "dorms = []\n",
    "for i in range(1,len(price),2):\n",
    "    dorms.append(price[i]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1d6ca020",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (Temp/ipykernel_7632/2286430916.py, line 33)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\BALLBU~1\\AppData\\Local\\Temp/ipykernel_7632/2286430916.py\"\u001b[1;36m, line \u001b[1;32m33\u001b[0m\n\u001b[1;33m    property_description.append(\"No Description\")  time.sleep(2)\u001b[0m\n\u001b[1;37m                                                   ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# scrape Hostels URL\n",
    "hostel_url = []\n",
    "\n",
    "while(True):\n",
    "    urls = driver.find_elements(By.XPATH,'//h2[@class=\"title title-6\"]/a')\n",
    "    for url in urls:\n",
    "        hostel_url.append(url.get_attribute(\"href\"))\n",
    "    time.sleep(2)    \n",
    "        \n",
    "    try:\n",
    "        next_button = driver.find_element(By.XPATH,'//div[@class=\"pagination-item pagination-prev\"]')\n",
    "        next_button.click()\n",
    "    except:\n",
    "        break\n",
    "        \n",
    "Rate = []\n",
    "for page in hostel_url:\n",
    "    driver.get(page)\n",
    "    \n",
    "    # Rating\n",
    "    try:\n",
    "        ratings = driver.find_element(By.XPATH,'//*[@id=\"__layout\"]/div/div[1]/section/div[6]/div/div[1]/div[1]/div[1]')\n",
    "        Rate.append(ratings.text)\n",
    "    except NoSuchElementException:\n",
    "        Rate.append(\"No Rating\")  \n",
    "    time.sleep(2)\n",
    "    \n",
    "    # Property Description\n",
    "    try:\n",
    "        pd = driver.find_element(By.XPATH,'//*[@id=\"__layout\"]/div/div[1]/section/div[6]/div/div[2]/div[2]/div/div[2]')\n",
    "        property_description.append(pd.text)\n",
    "    except NoSuchElementException:\n",
    "        property_description.append(\"No Description\")  time.sleep(2)        \n",
    "# remove extra data from Rating     \n",
    "all_text = []\n",
    "for i in Rate:\n",
    "    all_text.append(i.split())\n",
    "time.sleep(2)\n",
    "\n",
    "for i in all_text:\n",
    "    Rating.append(i[0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "988399c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0 30 0 30 30 30 0\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    len(Hostel_Name),len(Distance),len(Rating),len(total_reviews),len(overall_review),\n",
    "    len(private),len(dorms),len(facilities),len(property_description))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7269d878",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "All arrays must be of the same length",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\BALLBU~1\\AppData\\Local\\Temp/ipykernel_7632/2254301594.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m Hostel=pd.DataFrame({\"Hostel Name\":Hostel_Name,\"Distance\":Distance,\"Rating\":Rating,\"Total Reviews\":total_reviews,\"Overall Review\":overall_review[:30],\n\u001b[0m\u001b[0;32m      2\u001b[0m                      \"Private Price\":private,\"Dorms Price\":dorms,\"Facilities\":facilities,\"Property Description\":property_description})\n\u001b[0;32m      3\u001b[0m \u001b[0mHostel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    612\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    613\u001b[0m             \u001b[1;31m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 614\u001b[1;33m             \u001b[0mmgr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict_to_mgr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtyp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmanager\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    615\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    616\u001b[0m             \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    462\u001b[0m         \u001b[1;31m# TODO: can we get rid of the dt64tz special case above?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    463\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 464\u001b[1;33m     return arrays_to_mgr(\n\u001b[0m\u001b[0;32m    465\u001b[0m         \u001b[0marrays\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtyp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtyp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconsolidate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    466\u001b[0m     )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, arr_names, index, columns, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    117\u001b[0m         \u001b[1;31m# figure out the index, if necessary\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 119\u001b[1;33m             \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_extract_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    120\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m             \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36m_extract_index\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    633\u001b[0m             \u001b[0mlengths\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_lengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    634\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 635\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"All arrays must be of the same length\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    636\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    637\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhave_dicts\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: All arrays must be of the same length"
     ]
    }
   ],
   "source": [
    "Hostel=pd.DataFrame({\"Hostel Name\":Hostel_Name,\"Distance\":Distance,\"Rating\":Rating,\"Total Reviews\":total_reviews,\"Overall Review\":overall_review[:30],\n",
    "                     \"Private Price\":private,\"Dorms Price\":dorms,\"Facilities\":facilities,\"Property Description\":property_description})\n",
    "Hostel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6b89d2a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method WebDriver.close of <selenium.webdriver.chrome.webdriver.WebDriver (session=\"b9b6f790ebdb2ceb55b971bb7c362be2\")>>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad67fcc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978b49c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
